<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title></title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <style type="text/css">
  /*
   * I add this to html files generated with pandoc.
   * Originally from https://gist.github.com/killercup/5917178
   */

  html {
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
  }

  body {
      color: #444;
      font-family: "Source Sans 3", Helvetica-Neue, Helvetica, Sans;
      line-height: 1.5;
      padding: 0.5em;
      margin: auto;
      max-width: 55em;
      background: #fefefe;
  }

  a {
      color: #2171b5;
      text-decoration: underline;
  }

  tr:nth-child(even) {background: #F8F8F8}
  tr:nth-child(odd) {background: #FFF}

  a:visited {
      color: #2171b5;
      text-decoration: none;
  }

  a:focus {
      outline: thin dotted;
  }

  *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  p {
      margin: 0.75em 0;
  }

  img {
      max-width: 60%;
      max-height:400px;
  }

  video {
      max-width: 60%;
  }


  h1, h2, h3, h4, h5, h6 {
      color: #111;
      line-height: 80%;
      margin-top: 1em;
      margin-bottom: 0.5em;
      font-weight: normal;
  }

  h1, h2, h3, h4, h5, h6 {
      font-weight: bold;
  }

  h1 {
      font-size: 2em;
      line-height: 1.25;
      color:  #084594;

  }

  h1.title {
      margin-top:0.2em;
      font-size: 2em;
      line-height: 1.25;
  }

  h2 {
      font-size: 1.5em;
      line-height: 1.6em;
          color:  #084594;
      padding-bottom: 3px;

  }

  h3 {
      font-size: 1.2em;
      line-height: 1.6em;
  }


  h4 {
      font-size: 1.2em;
      line-height: 1.4em;
  }

  h5 {
      font-size: 1em;
  }

  h6 {
      font-size: 0.9em;
  }

  blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #EEE solid;
  }

  hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 0.5em 0;
      padding: 0;
  }

  pre, code, kbd, samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: 'courier new', monospace;
      font-size: 0.98em;
  }

  pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
  }

  .answer {
      color:#CC0033;
      font-style:italic;
  }

  b, strong {
      font-weight: bold;
  }

  dfn {
      font-style: italic;
  }

  ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
  }

  mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
  }

  sub, sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
  }

  sup {
      top: -0.5em;
  }

  sub {
      bottom: -0.25em;
  }

  ul, ol {
      margin: 0.5em 0;
      padding: 0em 0em 0em 1em;
  }

  ul img {
      list-style-type: none;
  }

  li p:last-child {
      margin-bottom: 0;
  }

  hr {
      border-top:none;
      height:0px;
      clear:both;
  }

  ul ul, ol ol {
      margin: .3em 0;
  }

  dl {
      margin-bottom: 1em;
  }

  dt {
      font-weight: bold;
      margin-bottom: .8em;
  }

  dd {
      margin: 0 0 .8em 2em;
  }

  dd:last-child {
      margin-bottom: 0;
  }

  img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
  }

  figure {
      display: block;
      text-align: center;
      margin: 1em 0;
  }

  figure img {
      border: none;
      margin: 0 auto;
  }

  figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 .8em;
  }

  table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
  }

  table th {
      padding: .2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
  }

  table td {
      padding: .2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
  }

  .author {
      font-size: 1.2em;
      text-align: center;
  }

  @media only screen and (min-width: 480px) {
      body {
  	font-size: 14px;
      }
  }
  @media only screen and (min-width: 768px) {
      body {
  	font-size: 16px;
      }
  }
  @media print {
      * {
  	background: transparent !important;
  	color: black !important;
  	filter: none !important;
  	-ms-filter: none !important;
      }

      body {
  	font-size: 12pt;
  	max-width: 100%;
      }

      a, a:visited {
  	text-decoration: underline;
      }

      hr {
  	height: 1px;
  	border: 0;
  	border-bottom: 1px solid black;
      }

      a[href]:after {
  	content: " (" attr(href) ")";
      }

      abbr[title]:after {
  	content: " (" attr(title) ")";
      }

      .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
  	content: "";
      }

      pre, blockquote {
  	border: 1px solid #999;
  	padding-right: 1em;
  	page-break-inside: avoid;
      }

      tr, img {
  	page-break-inside: avoid;
      }

      img {
  	max-width: 40% !important;
      max-height: 300px !important;
      }

      @page :left {
  	margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
  	margin: 15mm 10mm 15mm 20mm;
      }

      p, h2, h3 {
  	orphans: 3;
  	widows: 3;
      }

      h2, h3 {
  	page-break-after: avoid;
      }
  }


  ldata {
  	font-size: 0.7em;
  	margin-bottom: 0em;
  	color:#808080;
  	font-style:italic;
  }

  danger {
  	color:#FF0000;
  	font-weight:bold;
  }

  correct {
  	color:#39C900;
  	font-weight:bold;
  }

  clg{
      color:#39C900;
  	font-weight:bold;
  }

  clr{
  	color:#FF0000;
  	font-weight:bold;
  }

  clb{
  	color:#0000CC;
  	font-weight:bold;
  }

  clp{
  	color:#6600FF;
  	font-weight:bold;
  }

  clk{
  	color:#708cef;
  	font-weight:bold;
  }

  clo{
  	color:#CC6600;
  	font-weight:bold;
  }

  sc{
          font-variant: small-caps;
  }

  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h3 id="this-presentation-is-available-online-at">This presentation is
available online at:</h3>
<p><a href="http://savethevowels.org/talks/ucsd_talk.html">http://savethevowels.org/talks/ucsd_talk.html</a></p>
<p>(Navigate with the arrow keys or on-screen controls)</p>
<hr />
<p><img width="50%" src="humorimg/thecount.jpg"></p>
<h1 id="n-gram-language-models">N-Gram Language Models</h1>
<h3 id="will-styler">Will Styler</h3>
<hr />
<h3 id="the-plan">The Plan</h3>
<ul>
<li><p>What are N-Grams?</p></li>
<li><p>Examples from the EnronSent Corpus</p></li>
<li><p>How N-Grams can form a language model</p></li>
<li><p>What is this model good for?</p></li>
<li><p>What are the strengths of N-Gram models?</p></li>
<li><p>What are their weaknesses?</p></li>
</ul>
<hr />
<h1 id="n-grams">N-grams</h1>
<hr />
<h3 id="what-is-an-n-gram">What is an N-gram?</h3>
<ul>
<li><p>An N-gram is a sequence of words that is N items long</p></li>
<li><p>1 word is a ‘unigram’, 2 is a ‘bigram’, 3 is a
‘trigram’…</p></li>
<li><p>We identify sequences in the text, then count their
frequencies</p></li>
<li><p>And that’s N-Gram analysis</p></li>
<li><p>“How often does this sequence of words occur?”</p></li>
</ul>
<hr />
<h3 id="how-do-we-find-n-gram-counts">How do we find N-Gram counts?</h3>
<ul>
<li><p>Choose a (large) corpus of text</p></li>
<li><p>Tokenize the words</p>
<ul>
<li>Break them into individual items based on knowledge about
language</li>
</ul></li>
<li><p>Count all individual words (using something like <a
href="https://www.nltk.org/">nltk</a>)</p>
<ul>
<li><p>Then all pairs of words…</p></li>
<li><p>Then all triplets…</p></li>
<li><p>All quadruplets…</p></li>
<li><p>… and so forth</p></li>
</ul></li>
<li><p>The end result is a table of counts by N-Gram</p></li>
</ul>
<hr />
<h2 id="lets-try-it">Let’s try it</h2>
<ul>
<li><p>We’ll use the <a
href="http://savethevowels.org/enronsent/">EnronSent Email
Corpus</a></p></li>
<li><p>~96,000 DOE-seized emails within the Enron Corporation from
2007</p></li>
<li><p>~14,000,000 words</p></li>
<li><p>This is a pretty small corpus for serious N-Gram work</p>
<ul>
<li><h2 id="but-its-a-nice-illustrative-case">But it’s a nice
illustrative case</h2></li>
</ul></li>
</ul>
<pre><code data-trim>

#!/usr/bin/env python

import nltk
from nltk import word_tokenize
from nltk.util import ngrams

es = open('enronsent_all.txt','r')
text = es.read()
token = nltk.word_tokenize(text)

unigrams = ngrams(token,1)
bigrams = ngrams(token,2)
trigrams = ngrams(token,3)
fourgrams = ngrams(token,4)
fivegrams = ngrams(token,5)

</code></pre>
<hr />
<h3 id="unigrams">Unigrams</h3>
<ul>
<li><p>‘The’ 560,524</p></li>
<li><p>‘to’ 418,221</p></li>
<li><p>‘Enron’ 391,190</p></li>
<li><p>‘Jeff’ 10,717</p></li>
<li><p>‘Veterinarian’ 2</p></li>
</ul>
<hr />
<h3 id="bigrams">Bigrams</h3>
<ul>
<li><p>‘of the’ 61935</p></li>
<li><p>‘need to’ 15303</p></li>
<li><p>‘at Enron’ 6384</p></li>
<li><p>‘forward to’ 4303</p></li>
<li><p>‘wordlessly he’ 2</p></li>
</ul>
<hr />
<h3 id="trigrams">Trigrams</h3>
<ul>
<li><p>‘Let me know’ 6821</p></li>
<li><p>‘If you have’ 5992</p></li>
<li><p>‘See attached file’ 2165</p></li>
<li><p>‘are going to’ 1529</p></li>
</ul>
<hr />
<h3 id="four-grams">Four-Grams</h3>
<ul>
<li><p>‘Please let me know’ 5512</p></li>
<li><p>‘Out of the office’ 947</p></li>
<li><p>‘Delete all copies of’ 765</p></li>
<li><p>‘Houston , TX 77002’ 646</p></li>
<li><p>‘you are a jerk’ 35</p></li>
</ul>
<hr />
<h3 id="five-grams">Five-Grams</h3>
<ul>
<li><p>‘If you have any questions’ 3294</p></li>
<li><p>‘are not the intended recipient’ 731</p></li>
<li><p>‘enforceable contract between Enron Corp.’ 418</p></li>
<li><p>‘wanted to let you know’ 390</p></li>
</ul>
<hr />
<h3 id="note-that-the-frequencies-of-occurrence-dropped-as-n-rose">Note
that the frequencies of occurrence dropped as N rose</h3>
<ul>
<li><p>‘The’ 560,524</p></li>
<li><p>‘of the’ 61,935</p></li>
<li><p>‘Let me know’ 6,821</p></li>
<li><p>‘Please let me know’ 5,512</p></li>
<li><p>‘If you have any questions’ 3,294</p></li>
<li><p><em>We’ll come back to this later</em></p></li>
</ul>
<hr />
<h3 id="ok-great.">OK, Great.</h3>
<ul>
<li><p>You counted words. Congratulations.</p></li>
<li><p><strong>What does this win us?</strong></p></li>
</ul>
<hr />
<h3 id="n-grams-give-us-more-than-just-counts">N-Grams give us more than
just counts</h3>
<ul>
<li><p>If we know how often Word X follows Word Y (rather than Word
Z)…</p></li>
<li><p><strong>“What is the probability of word X following word
Y?”</strong></p>
<ul>
<li><p>p(me|let) &gt; p(flamingo|let)</p></li>
<li><p>We calculate log probabilities to avoid descending to
zero</p></li>
</ul></li>
<li><p>Probabilities are more useful than counts</p></li>
<li><p><strong>Probabilities allow us to predict</strong></p></li>
</ul>
<hr />
<h3 id="n-grams-can-give-us-a-language-model">N-Grams can give us a
language model</h3>
<ul>
<li><p>Answers “Is this likely to be a grammatical sentence?”</p></li>
<li><p>Any natural language processing application needs a language
model</p></li>
<li><p>We can get a surprisingly rich model from N-Gram-derived
information alone</p></li>
</ul>
<hr />
<h3 id="these-probabilities-tell-us-about-grammar">These probabilities
tell us about Grammar</h3>
<ul>
<li><p>“You are” (11,294 occurrences) is more likely than “You is” (286
occurrences)</p></li>
<li><p>“Would have” (2362) is more likely than “Would of” (17)</p></li>
<li><p>“Might be able to” (240) is more common than “might could”
(4)</p>
<ul>
<li>“Thought Scott might could use some help…”</li>
</ul></li>
<li><p>“Two agreements” (35) is more likely than “Two agreement”
(2)</p></li>
<li><p>“Throw in” (35) and “Throw out” (33) are much more common than
‘Throw’ + other prepositions</p></li>
<li><p><strong>n-grams provide a very simple <em>language model</em>
from which we can do inference</strong></p></li>
</ul>
<hr />
<h3 id="these-probabilities-tell-us-about-the-world">These probabilities
tell us about the world</h3>
<ul>
<li><p>Probabilities of language are based in part on our interaction
with the world</p></li>
<li><p>People at Enron ‘go to the’ bathroom (17), Governor (7), Caymans
(6), assembly (6), and senate (5)</p></li>
<li><p>People at Enron enjoy good food (18), Mexican Food (17), Fast
Food (13), Local Food (4), and Chinese Food (2)</p>
<ul>
<li>But “Californian Food” isn’t a thing</li>
</ul></li>
<li><p>Power comes from California (9), Generators (6), EPMI (3), and
Canada (2)</p>
<ul>
<li>… and mostly gets sold to California (29)</li>
</ul></li>
<li><p><strong>Probable groupings tell us something about how this world
works</strong></p></li>
</ul>
<hr />
<h3 id="n-gram-models-are-really-useful">N-Gram models are
<em>really</em> useful</h3>
<ul>
<li><p>Provide some grammatical information</p>
<ul>
<li>“What word forms regularly occur together?”</li>
</ul></li>
<li><p>Provide some real-world information</p>
<ul>
<li>“What are people most commonly talking about?”</li>
</ul></li>
<li><p>They can solve real world problems</p></li>
</ul>
<hr />
<h3 id="n-gram-uses-in-the-real-world">N-Gram uses in the real
world</h3>
<ul>
<li><p>Predictive typing</p>
<ul>
<li>And don’t have the time or two of them and they said let’s say that
you have to be at the house in a bit of traffic …</li>
</ul></li>
<li><p>Speech recognition</p>
<ul>
<li><p>“I took a walk for exercise”</p></li>
<li><p>“I need a wok for stir fry”</p></li>
</ul></li>
<li><p>Typo detection</p>
<ul>
<li><p>“I made a bog mistake”</p></li>
<li><p>“She got lost in a peat big”</p></li>
</ul></li>
<li><p>Sentiment analysis</p>
<ul>
<li>How often do “Toyota” and “awful” co-occur relative to “Nissan” and
“awful”?</li>
</ul></li>
</ul>
<hr />
<h3 id="sociolinguistic-n-gramming">Sociolinguistic n-gramming</h3>
<ul>
<li><p>“How often is word X used to describe black athletes vs. white
athletes?”</p>
<ul>
<li><p>“Is Unigram frequency of these words predicted by subject
race?”</p></li>
<li><p>“What about racially loaded bigrams?”</p></li>
</ul></li>
<li><p>Words like “Aggressive”, “Angry”, “Unstoppable” and “Ferocious”
are preferentially applied to black athletes</p></li>
<li><p>Work is ongoing</p>
<ul>
<li>c.f <a
href="https://www.researchgate.net/publication/317425125_The_Reflection_and_Reification_of_Racialized_Language_in_Popular_Media">Wright
2017, The Reflection and Reification of Racialized Language in Popular
Media</a></li>
</ul></li>
</ul>
<hr />
<h2 id="and-all-of-this-comes-from-counting-words">… and all of this
comes from counting words</h2>
<hr />
<h2 id="n-gram-modeling-strengths">N-Gram Modeling Strengths</h2>
<hr />
<h3 id="n-gram-modeling-is-relatively-simple">N-Gram Modeling is
relatively simple</h3>
<ul>
<li><p>Easy to understand and implement conceptually</p></li>
<li><p>Syntax and semantics don’t need to be understood</p></li>
<li><p>You don’t need to annotate a corpus or build ontologies</p></li>
<li><p><em>As long as you can tokenize the words, you can do an N-Gram
analysis</em></p></li>
<li><p>Makes it possible for datasets where other NLP tools might not
work</p></li>
<li><p>A basic language model comes for free</p></li>
</ul>
<hr />
<h3 id="n-gram-modeling-is-easily-scalable">N-Gram Modeling is easily
scalable</h3>
<ul>
<li><p>It works the same on 1000 words or 100,000,000 words</p></li>
<li><p>Modest computing requirements</p></li>
<li><p>More data means a better model</p>
<ul>
<li><p>You see more uses of more N-Grams</p></li>
<li><p>Your ability to look at higher Ns is limited by your
dataset</p></li>
<li><p>Probabilities become more defined</p></li>
</ul></li>
<li><p>… and we have a LOT of data</p></li>
</ul>
<hr />
<h2 id="n-gram-modeling-weaknesses">N-Gram Modeling Weaknesses</h2>
<hr />
<h3 id="they-only-work-with-strict-juxtaposition">They only work with
strict juxtaposition</h3>
<ul>
<li><p>“The tall giraffe ate.” and “The giraffe that ate was tall.”</p>
<ul>
<li>We view these both as linking “Giraffe” and “Tall”, but the model
doesn’t</li>
</ul></li>
<li><p>“The angry young athlete” and “The angry old athlete”</p>
<ul>
<li>These won’t register as tri-gram matches</li>
</ul></li>
<li><p>Windowed association models and Latent Semantic Analysis are
better at finding co-occurrence</p></li>
</ul>
<hr />
<h3 id="very-poor-at-handling-uncommon-or-unattested-n-grams">Very poor
at handling uncommon or unattested N-Grams</h3>
<ul>
<li><p>Models are only good at estimating items they’ve seen
previously</p></li>
<li><p>“Her Onco-Endocrinologist resected Leticia’s carcinoma”</p></li>
<li><p>“Bacon flamingo throughput demyelination ngarwhagl”</p></li>
<li><p>This is is why <em>smoothing</em> is crucial</p>
<ul>
<li><p>Assigning very low probabilities to unattested
combinations</p></li>
<li><p>… and why more data means better N-Grams</p></li>
</ul></li>
</ul>
<hr />
<h3 id="n-gram-models-are-missing-information">N-Gram models are missing
information</h3>
<ul>
<li><p>Syntax, Coreference, and Part of Speech tagging provide important
information</p></li>
<li><p>“You are” is more likely than “You is” (286 occurrences)</p>
<ul>
<li>“… the number I have given you is my cell phone…”</li>
</ul></li>
<li><p>“I bought an awful Toyota.” vs. “I bought a Toyota. It’s
awful.”</p>
<ul>
<li>No juxtaposition without resolving anaphora</li>
</ul></li>
<li><p>“Time flies like an arrow, fruit flies like a banana”</p>
<ul>
<li>Part-of-speech distinguishes these bigrams</li>
</ul></li>
<li><p><strong>There’s more to language than
juxtaposition</strong></p></li>
</ul>
<hr />
<h2 id="conclusion">Conclusion</h2>
<hr />
<h3 id="n-grams-arent-the-solution-to-every-problem">N-Grams aren’t the
solution to every problem</h3>
<ul>
<li><p>They’re missing crucial information about linguistic
structure</p></li>
<li><p>They handle uncommon and unattested forms poorly</p></li>
<li><p>They only work with strict juxtaposition</p></li>
</ul>
<hr />
<h3 id="n-gram-models-are-a-powerful-tool-for-nlp">N-Gram Models are a
powerful tool for NLP</h3>
<ul>
<li><p>They’re simple</p></li>
<li><p>They have minimal requirements for the data</p></li>
<li><p>They provide rich information when used intelligently</p></li>
<li><p>And they scale beautifully with the sorts of huge datasets
available today</p></li>
</ul>
<hr />
<h2 id="n-grams-are-not-the-only-tool-we-need-to-model-language">N-Grams
are not the only tool we need to model language</h2>
<ul>
<li>… but they are a really excellent start</li>
</ul>
<hr />
<h2 id="questions">Questions?</h2>
<hr />
<p><img class="big" src="humorimg/now_for_something_completely_different.jpg"></p>
<hr />
<p><img width="50%" src="phonmedia/vowelformants.gif"></p>
<h1 id="vowel-formants-the-source-and-the-filter">Vowel Formants, the
Source, and the Filter</h1>
<h2 id="will-styler-1">### Will Styler</h2>
<h3
id="the-source-filter-dichotomy-is-a-threshold-concept-in-acoustic-phonetics">The
Source-Filter Dichotomy is a ‘threshold concept’ in Acoustic
Phonetics</h3>
<ul>
<li><p>Important for understanding speech production and
perception</p></li>
<li><p>Key to being able to discuss vowel formants</p></li>
<li><p>Useful for understanding many elements of acoustics</p></li>
</ul>
<hr />
<h3 id="the-plan-1">The Plan</h3>
<ul>
<li><p>How are we going to visualize sound today?</p></li>
<li><p>What are vowel formants? (Practically)</p></li>
<li><p>The Source-Filter Model of Speech Production</p></li>
<li><p>Vowel formants and resonance</p></li>
<li><p>Source-Filter Independence</p></li>
</ul>
<hr />
<h2 id="three-ways-to-visualize-sound">Three Ways to Visualize
Sound</h2>
<hr />
<h3 id="waveforms">Waveforms</h3>
<p><img width="70%" src="phonmedia/noisewaveform.png"></p>
<audio controls>
<source src="phonmedia/noise.wav" type="audio/wav">
</audio>
<hr />
<h3 id="spectral-slice-fft">Spectral Slice (FFT)</h3>
<p><img width="70%" src="phonmedia/noisefft.jpg"></p>
<hr />
<h3 id="spectrograms">Spectrograms</h3>
<p><img width="70%" src="phonmedia/noisebbspectrogram.png"></p>
<hr />
<h2 id="vowel-formants">Vowel Formants</h2>
<hr />
<h3
id="we-talk-about-vowel-formants-a-great-deal-in-acoustic-phonetics">We
talk about vowel formants a great deal in acoustic phonetics</h3>
<ul>
<li><p>We measure them for vowel production</p></li>
<li><p>We talk about them in vowel perception</p></li>
<li><p>They’re useful cues for consonants</p></li>
<li><p>They’re one of the first things people gravitate to in
spectrograms</p></li>
</ul>
<hr />
<h3 id="we-see-formants-in-spectrograms">We see formants in
spectrograms</h3>
<p><img width="70%" src="phonmedia/noisebbspectrogram.png"></p>
<hr />
<h3 id="we-label-them-as-f1-f2-and-f3">We label them as F1, F2, and
F3</h3>
<p><img width="50%" src="phonmedia/vowelformants_diagram.png"></p>
<hr />
<h3
id="the-frequency-of-vowel-formants-is-main-cue-for-perceiving-vowels-in-english">The
frequency of Vowel formants is main cue for perceiving vowels in
English</h3>
<p><img width="70%" src="phonmedia/vowelformants.gif"></p>
<ul>
<li>… and they’re helpful for perceiving consonants too!</li>
</ul>
<hr />
<h3 id="but-what-are-they-really">But what <em>are</em> they,
really?</h3>
<hr />
<h2 id="the-source-filter-model-of-speech-production">The Source-Filter
Model of Speech Production</h2>
<hr />
<h3 id="lets-talk-about-the-vocal-tract">Let’s talk about the vocal
tract</h3>
<p><img width="20%" src="phonmedia/sagittalsection_source.png"><img width="20%" src="phonmedia/sagittalsection_filter.png"></p>
<p>‘Source’ and ‘Filter’</p>
<hr />
<h3 id="source-the-vocal-folds">Source (The Vocal Folds)</h3>
<p><img width="20%" src="phonmedia/sagittalsection_source.png"></p>
<hr />
<h3 id="source-the-vocal-folds-1">Source (The Vocal Folds)</h3>
<p><img width="40%" src="phonmedia/larynx_glottis.jpg"></p>
<ul>
<li>The vocal folds produce signal with a given fundamental frequency
(f0) and evenly spaced harmonics.</li>
</ul>
<hr />
<h3 id="this-source-signal-is-not-so-pretty">This source signal is not
so pretty</h3>
<p><img width="70%" src="phonmedia/voicing_filtered_fft.png"></p>
<audio controls>
<source src="phonmedia/voicing.wav" type="audio/wav">
</audio>
<hr />
<h3 id="this-source-signal-is-not-so-pretty-1">This source signal is not
so pretty</h3>
<p><img width="70%" src="phonmedia/voicing_filtered_spectrogram.png"></p>
<audio controls>
<source src="phonmedia/voicing.wav" type="audio/wav">
</audio>
<hr />
<h3 id="this-signal-carries-pitch-information-but-not-much-else">This
signal carries pitch information, but not much else</h3>
<ul>
<li>Everything else happens in the…</li>
</ul>
<hr />
<h3 id="filter-the-vocal-tract">Filter (The Vocal Tract)</h3>
<p><img width="20%" src="phonmedia/sagittalsection_filter.png"></p>
<ul>
<li><p>Filters that ugly signal by changing the position of
articulators</p></li>
<li><p>What do I mean by filter?</p></li>
</ul>
<hr />
<h3 id="resonance">Resonance</h3>
<p><img width="20%" src="phonmedia/resonance_tubes.png"></p>
<ul>
<li><p>Some wavelengths ‘fit’ well within a cavity of a given size or
shape</p></li>
<li><p>Sound at those wavelengths will grow stronger because they
‘resonate’</p></li>
<li><p>Sound at other wavelengths will grow quieter and are
‘damped’</p></li>
</ul>
<hr />
<h3 id="we-all-understand-resonance">We all understand resonance</h3>
<p><img width="50%" src="img/bathtub.png"></p>
<hr />
<h3 id="resonant-cavities-act-like-filters">Resonant Cavities act like
filters</h3>
<ul>
<li><p>Some frequencies are made stronger</p></li>
<li><p>Some are made weaker</p></li>
<li><p>Some are unaffected</p></li>
<li><p>… and this is how vowels work</p></li>
</ul>
<hr />
<h3 id="the-vocal-tract-filters-the-source">The vocal tract filters the
source</h3>
<ul>
<li><p>Changing the position of the articulators affects the size and
shape of the cavity</p></li>
<li><p><em>Changing the position of articulators in your vocal tract
affects resonances</em></p></li>
</ul>
<hr />
<h3 id="we-take-something-boring">We take something boring</h3>
<p><img width="70%" src="phonmedia/voicing_filtered_spectrogram.png"></p>
<p>(The source signal)</p>
<hr />
<h3 id="and-filter-it-into-something-beautiful">… and filter it into
something beautiful</h3>
<p><img width="70%" src="phonmedia/noisebbspectrogram.png"></p>
<hr />
<p><img width="50%" src="img/magic.jpg"></p>
<hr />
<h3 id="different-vowels-are-just-different-cavity-shapes">Different
vowels are just different cavity shapes</h3>
<p><img width="40%" src="phonmedia/voweltongue2.png"></p>
<hr />
<h3 id="each-cavity-shape-produces-different-resonances">Each cavity
shape produces different resonances</h3>
<p><img width="70%" src="phonmedia/vowelformants.gif"></p>
<hr />
<h3
id="changes-in-tongue-position-mean-changes-in-formant-structure">Changes
in tongue position mean changes in formant structure</h3>
<p><img width="70%" src="phonmedia/vowelformantsarticulation.png"></p>
<hr />
<h3 id="a-creepy-demonstration">A (creepy) demonstration</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qobhDJ_vEOc?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
<hr />
<h3 id="so-we-have-a-source-and-a-filter">So, we have a source, and a
filter</h3>
<ul>
<li><p>The larynx produces a signal with lots of harmonics</p></li>
<li><p>The rest of the vocal tract filters it into something we
recognize as “speech”</p></li>
</ul>
<hr />
<h3 id="perceiving-vowels-using-formants">Perceiving vowels using
formants</h3>
<ul>
<li><p>Vowel perception is formant based</p>
<ul>
<li>Although duration, nasality, and other features can play a
role!</li>
</ul></li>
<li><p>Formants give us information about what the tongue is doing
<em>even when no closures are being made</em></p></li>
<li><p>Formants tell me what your tongue is doing in the mouth!</p></li>
</ul>
<hr />
<h3 id="measuring-vowels-using-formants">Measuring vowels using
formants</h3>
<ul>
<li><p>Studying vowel quality is usually done using formants</p>
<ul>
<li>Although Ultrasound and MRI are possible too</li>
</ul></li>
<li><p>Formants tell me what your tongue is doing in the mouth</p>
<ul>
<li>So changes in formants map to changes in articulation</li>
</ul></li>
</ul>
<hr />
<h2 id="but-where-are-they">But <em>where are they?!</em></h2>
<hr />
<h3 id="harmonics-are-not-formants">Harmonics are not formants!</h3>
<ul>
<li><p>“The vocal folds produce harmonics”</p></li>
<li><p>“Resonance changes harmonics, does it create separate
formants?”</p></li>
<li><p><strong>“Where can I see the formants in a spectral
slice?”</strong></p></li>
</ul>
<hr />
<h3
id="formants-are-obvious-when-youre-looking-at-sounds-from-a-distance">Formants
are obvious when you’re looking at sounds from a distance</h3>
<ul>
<li>They show up better when you’re not as sharply focused on
frequency</li>
</ul>
<p><img width="70%" src="phonmedia/noisebbspectrogram.png"></p>
<hr />
<p><img width="70%" src="phonmedia/noisefft.jpg"></p>
<ul>
<li><strong>“Where’d the formants go?!”</strong></li>
</ul>
<hr />
<h3 id="a-more-grounded-example">A more grounded example</h3>
<p><img src="phonmedia/topo_no_axes.png"></p>
<hr />
<p><img class="big" src="phonmedia/topo_map.png"></p>
<table style="width:6%;">
<colgroup>
<col style="width: 5%" />
</colgroup>
<tbody>
<tr class="odd">
<td><img class="big" src="phonmedia/topo_labeled.png"></td>
</tr>
</tbody>
</table>
<p><img src="phonmedia/topo_ranges.png"></p>
<hr />
<h3 id="formants-are-the-ranges-not-the-mountains">Formants are the
ranges, not the mountains!</h3>
<p><img width="70%" src="phonmedia/ispectrum.png"></p>
<hr />
<h3
id="formants-are-the-areas-of-the-spectrum-where-harmonics-resonate">Formants
are the areas of the spectrum where harmonics resonate</h3>
<ul>
<li><p>Where harmonics of the source are amplified, rather than
damped</p></li>
<li><p>This indicates certain positions for the tongue in the mouth</p>
<ul>
<li>… and that’s what we’re listening for when identifying vowels and
consonants</li>
</ul></li>
</ul>
<hr />
<p>One final, crucial point…</p>
<hr />
<h2 id="source-and-filter-are-independent">Source and Filter are
Independent</h2>
<hr />
<h3 id="the-filter-will-filter-any-source-signal">The Filter will filter
any source signal</h3>
<p><img width="70%" src="phonmedia/source_filter_independence.png"></p>
<p><a
href="http://www.haskins.yale.edu/featured/heads/mmsp/acoustic.html">Image
Credit</a></p>
<hr />
<h3 id="changing-pitch-doesnt-change-the-resonances">Changing Pitch
doesn’t change the resonances</h3>
<p><img width="70%" src="phonmedia/sourcefilter_changepitch_broad.png"></p>
<audio controls>
<source src="phonmedia/sourcefilter_changepitch.wav" type="audio/wav">
</audio>
<hr />
<h3 id="changing-resonances-doesnt-change-pitch">Changing resonances
doesn’t change pitch</h3>
<p><img width="70%" src="phonmedia/sourcefilter_changeformants_broad.png"></p>
<audio controls>
<source src="phonmedia/sourcefilter_changeformants.wav" type="audio/wav">
</audio>
<hr />
<h3 id="voice-pitch-is-unrelated-to-resonance.">Voice pitch is unrelated
to resonance.</h3>
<ul>
<li><strong>Resonance is unrelated to voice pitch.</strong></li>
</ul>
<hr />
<h3 id="in-fact-there-are-lots-of-sources-possible">In fact, there are
lots of sources possible</h3>
<ul>
<li>… which is good news for people who no longer have a larynx</li>
</ul>
<hr />
<h3 id="electrolaryngeal-speech">Electrolaryngeal Speech</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/riHLUOXt1Aw?rel=0&amp;start=15" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
<hr />
<h3 id="esophageal-speech">Esophageal Speech</h3>
<p><img width="20%" src="phonmedia/sagittalsection_source.png"></p>
<hr />
<h3 id="esophageal-speech-1">Esophageal Speech</h3>
<iframe width="560" height="315" src="https://www.youtube.com/embed/kyN_NFoBfiw?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen>
</iframe>
<hr />
<p><img width="70%" src="img/bearsrepeating.jpg"></p>
<h3 id="the-source-and-the-filter-are-independent">The Source and the
Filter are Independent</h3>
<hr />
<h2 id="final-conclusions">Final conclusions</h2>
<hr />
<h2 id="take-home-points">Take-home points</h2>
<ul>
<li><p>The vocal folds provide a source signal for speech</p></li>
<li><p>The rest of the vocal tract filters that source into identifiable
sounds</p></li>
<li><p>We call those ranges of harmonics that resonate with a certain
articulation “Formants”</p></li>
<li><p>These resonances tell us how the vocal tract is being shaped at
that moment</p></li>
<li><p>Formants are crucial for percieving (and measuring)
vowels</p></li>
<li><p>The Source and the Filter are independent</p></li>
</ul>
<hr />
<p>… And vowel acoustics are really, <em>really</em> cool!</p>
<p><img width="50%" src="img/magic.jpg"></p>
<hr />
<h3 id="questions-1">Questions?</h3>
<hr />
<h3 id="this-presentation-is-available-online-at-1">This presentation is
available online at:</h3>
<p><a href="http://savethevowels.org/talks/ucsd_talk.html">http://savethevowels.org/talks/ucsd_talk.html</a></p>
<hr />
<h3 id="thank-you">Thank you!</h3>
<hr />
</body>
</html>
