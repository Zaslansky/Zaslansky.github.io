<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title></title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <style type="text/css">
  /*
   * I add this to html files generated with pandoc.
   * Originally from https://gist.github.com/killercup/5917178
   */

  html {
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
  }

  body {
      color: #444;
      font-family: "Source Sans 3", Helvetica-Neue, Helvetica, Sans;
      line-height: 1.5;
      padding: 0.5em;
      margin: auto;
      max-width: 55em;
      background: #fefefe;
  }

  a {
      color: #2171b5;
      text-decoration: underline;
  }

  tr:nth-child(even) {background: #F8F8F8}
  tr:nth-child(odd) {background: #FFF}

  a:visited {
      color: #2171b5;
      text-decoration: none;
  }

  a:focus {
      outline: thin dotted;
  }

  *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  p {
      margin: 0.75em 0;
  }

  img {
      max-width: 60%;
      max-height:400px;
  }

  video {
      max-width: 60%;
  }


  h1, h2, h3, h4, h5, h6 {
      color: #111;
      line-height: 80%;
      margin-top: 1em;
      margin-bottom: 0.5em;
      font-weight: normal;
  }

  h1, h2, h3, h4, h5, h6 {
      font-weight: bold;
  }

  h1 {
      font-size: 2em;
      line-height: 1.25;
      color:  #084594;

  }

  h1.title {
      margin-top:0.2em;
      font-size: 2em;
      line-height: 1.25;
  }

  h2 {
      font-size: 1.5em;
      line-height: 1.6em;
          color:  #084594;
      padding-bottom: 3px;

  }

  h3 {
      font-size: 1.2em;
      line-height: 1.6em;
  }


  h4 {
      font-size: 1.2em;
      line-height: 1.4em;
  }

  h5 {
      font-size: 1em;
  }

  h6 {
      font-size: 0.9em;
  }

  blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #EEE solid;
  }

  hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 0.5em 0;
      padding: 0;
  }

  pre, code, kbd, samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: 'courier new', monospace;
      font-size: 0.98em;
  }

  pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
  }

  .answer {
      color:#CC0033;
      font-style:italic;
  }

  b, strong {
      font-weight: bold;
  }

  dfn {
      font-style: italic;
  }

  ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
  }

  mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
  }

  sub, sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
  }

  sup {
      top: -0.5em;
  }

  sub {
      bottom: -0.25em;
  }

  ul, ol {
      margin: 0.5em 0;
      padding: 0em 0em 0em 1em;
  }

  ul img {
      list-style-type: none;
  }

  li p:last-child {
      margin-bottom: 0;
  }

  hr {
      border-top:none;
      height:0px;
      clear:both;
  }

  ul ul, ol ol {
      margin: .3em 0;
  }

  dl {
      margin-bottom: 1em;
  }

  dt {
      font-weight: bold;
      margin-bottom: .8em;
  }

  dd {
      margin: 0 0 .8em 2em;
  }

  dd:last-child {
      margin-bottom: 0;
  }

  img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
  }

  figure {
      display: block;
      text-align: center;
      margin: 1em 0;
  }

  figure img {
      border: none;
      margin: 0 auto;
  }

  figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 .8em;
  }

  table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
  }

  table th {
      padding: .2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
  }

  table td {
      padding: .2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
  }

  .author {
      font-size: 1.2em;
      text-align: center;
  }

  @media only screen and (min-width: 480px) {
      body {
  	font-size: 14px;
      }
  }
  @media only screen and (min-width: 768px) {
      body {
  	font-size: 16px;
      }
  }
  @media print {
      * {
  	background: transparent !important;
  	color: black !important;
  	filter: none !important;
  	-ms-filter: none !important;
      }

      body {
  	font-size: 12pt;
  	max-width: 100%;
      }

      a, a:visited {
  	text-decoration: underline;
      }

      hr {
  	height: 1px;
  	border: 0;
  	border-bottom: 1px solid black;
      }

      a[href]:after {
  	content: " (" attr(href) ")";
      }

      abbr[title]:after {
  	content: " (" attr(title) ")";
      }

      .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
  	content: "";
      }

      pre, blockquote {
  	border: 1px solid #999;
  	padding-right: 1em;
  	page-break-inside: avoid;
      }

      tr, img {
  	page-break-inside: avoid;
      }

      img {
  	max-width: 40% !important;
      max-height: 300px !important;
      }

      @page :left {
  	margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
  	margin: 15mm 10mm 15mm 20mm;
      }

      p, h2, h3 {
  	orphans: 3;
  	widows: 3;
      }

      h2, h3 {
  	page-break-after: avoid;
      }
  }


  ldata {
  	font-size: 0.7em;
  	margin-bottom: 0em;
  	color:#808080;
  	font-style:italic;
  }

  danger {
  	color:#FF0000;
  	font-weight:bold;
  }

  correct {
  	color:#39C900;
  	font-weight:bold;
  }

  clg{
      color:#39C900;
  	font-weight:bold;
  }

  clr{
  	color:#FF0000;
  	font-weight:bold;
  }

  clb{
  	color:#0000CC;
  	font-weight:bold;
  }

  clp{
  	color:#6600FF;
  	font-weight:bold;
  }

  clk{
  	color:#708cef;
  	font-weight:bold;
  }

  clo{
  	color:#CC6600;
  	font-weight:bold;
  }

  sc{
          font-variant: small-caps;
  }

  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="speech-codecs-and-encryption">Speech Codecs and Encryption</h1>
<h3 id="will-styler---lign-168">Will Styler - LIGN 168</h3>
<hr />
<h3 id="now-we-know-what-sound-looks-like">Now we know what sound looks
like</h3>
<ul>
<li><p>We know how to save it in an uncompressed file</p></li>
<li><p>We know how we can compress sounds for storage or
transmission</p></li>
<li><p>… but isn’t speech special?</p></li>
</ul>
<hr />
<h3 id="todays-plan">Today’s Plan</h3>
<ul>
<li><p>Is speech special?</p></li>
<li><p>What are speech codecs?</p></li>
<li><p>Why is bitrate is so important for speech?</p></li>
<li><p>How do speech codecs work?</p></li>
<li><p>Voice Encryption</p></li>
</ul>
<hr />
<h2 id="is-speech-special">Is Speech Special?</h2>
<hr />
<h3 id="this-is-a-huge-open-question-in-speech-perception">This is a
huge open question in speech perception</h3>
<ul>
<li><p>Some theories treat speech perception like any other sound
perception task</p>
<ul>
<li><p>“We connect acoustic signatures to specific speech sounds like we
do any other”</p></li>
<li><p>“Modeling the acoustics of the inside of a face is much like
modeling the acoustics of the inside of a room”</p></li>
</ul></li>
<li><p>Some theories treat speech as special</p>
<ul>
<li><p>“Our perception of linguistic sound is <em>fundamentally
different</em> than our perception of other sounds”</p></li>
<li><p>“We understand how human speech is made, so we use that specific
knowledge to understand spoken language”</p></li>
</ul></li>
</ul>
<hr />
<h3
id="luckily-we-dont-have-to-solve-that-problem-in-speech-processing">Luckily,
we don’t have to solve that problem in Speech Processing</h3>
<ul>
<li>We ask a simpler question…</li>
</ul>
<hr />
<h3
id="do-we-get-better-results-when-we-treat-speech-as-different-from-any-other-environmental-sound">Do
we get better results when we treat speech as different from any other
environmental sound?</h3>
<ul>
<li><p>Are we able to <em>analyze</em> speech more effectively by using
speech-specific algorithms?</p></li>
<li><p>Are we able to <em>compress</em> speech more effectively by using
speech-specific algorithms?</p></li>
<li><p>Are we able to <em>recognize</em> speech more effectively by
using speech-specific algorithms?</p></li>
<li><p>Are we able to <em>generate</em> speech more effectively by using
speech-specific algorithms?</p></li>
</ul>
<hr />
<h3
id="are-linguists-necessary-or-helpful-when-doing-computational-speech-processing">Are
linguists necessary or helpful when doing computational speech
processing?</h3>
<hr />
<h3 id="speech-can-also-be-especially-problematic">Speech can also be
especially problematic</h3>
<ul>
<li><p>We are very sensitive to problems with the speech signal</p></li>
<li><p>Nuances which we might not notice in music are very noticeable in
your BFF’s voice on Zoom</p></li>
<li><p>Tiny changes in the signal can have an outsized perceptual impact
on speech</p></li>
<li><p>It’s very easy for a speech signal to sound ‘robotic’ or
‘distorted’</p></li>
</ul>
<hr />
<h3 id="so-far-speech-hasnt-been-very-special">So far, speech hasn’t
been very special</h3>
<ul>
<li><p>Analyzing Sound and Analyzing Speech are often done using the
same tools</p></li>
<li><p>LPC was developed for speech, but is used for sound more
generally!</p></li>
<li><p>MFCC was developed for speech, but is used for sound more
generally!</p></li>
<li><p>Speech signal processing has driven general sound
processing!</p></li>
</ul>
<hr />
<h3
id="well-keep-seeing-this-question-as-we-move-through-the-quarter">We’ll
keep seeing this question as we move through the quarter!</h3>
<ul>
<li>Today, we’ll think about compression!</li>
</ul>
<hr />
<h2 id="speech-codecs">Speech Codecs</h2>
<hr />
<h3 id="review-codecs">Review: Codecs</h3>
<ul>
<li><p>A ‘codec’ is used to encode and decode a signal</p></li>
<li><p>Often, codecs include some degree of compression</p></li>
<li><p>Many different codecs exist for the same kind of data</p></li>
</ul>
<hr />
<h3 id="weve-talked-about-a-number-of-codecs-already">We’ve talked about
a number of codecs already</h3>
<ul>
<li><p>FLAC is a great lossless audio codec which works <em>for any
audio</em></p></li>
<li><p>mp3 and AAC are great lossy audio codecs which work <em>for any
audio</em></p></li>
<li><p>Opus is a great free and lossy audio codec which works <em>for
any audio</em></p></li>
</ul>
<hr />
<h3
id="compression-works-better-when-we-throw-out-more-information">Compression
works better when we throw out more information</h3>
<ul>
<li><p>It’s easier to compress a file when we know which frequencies
aren’t relevant and which are</p></li>
<li><p>Signals with a known kind and structure are easier to model more
completely</p>
<ul>
<li>When you model the signal better, you save fewer residuals</li>
</ul></li>
<li><p>Signals with strong autocorrelation and slow transitions are
easier to model completely</p></li>
<li><p>Psychoacoustic knowledge about <em>what’s most important</em>
allows us to make better decisions about what we throw away</p></li>
<li><p><strong>So, do we compress better when we make a speech-specific
codec?</strong></p></li>
</ul>
<hr />
<h3
id="speech-codecs-are-designed-to-do-better-with-speech-than-anything-else">Speech
Codecs are designed to do better with speech than anything else</h3>
<ul>
<li><p>“We know what speech is like, so let’s focus doing that better
than anything else”</p></li>
<li><p>“We’re going to assume everything coming through is speech, and
compress accordingly”</p></li>
<li><p>“I don’t care if it makes music sound worse, that’s not what
we’re trying to do here!”</p></li>
<li><p>“I have very little bandwidth available, and I want to use all of
it for the things that make speech understandable”</p></li>
</ul>
<hr />
<h3 id="well-known-speech-codecs">Well-known speech codecs</h3>
<ul>
<li><p><strong>G.711</strong>: This is what Campus Phones and Landline
networks now use</p></li>
<li><p><strong>Adaptive Multi-Rate (AMR)</strong>: Used to compress
speech on cell networks. Will be replaced by…</p></li>
<li><p><strong>Enhanced Voice Services (EVS)</strong>: The next-gen,
‘5G’ codec for cell phone use</p></li>
<li><p><strong>Speex</strong>: A speech-focused codec for low-bandwidth
situation, largely replaced by…</p></li>
<li><p><strong>Opus</strong>: A general purpose codec, but with a strong
speech subsystem</p></li>
</ul>
<hr />
<h2 id="why-does-bitrate-matter-so-much">Why does bitrate matter so
much?</h2>
<hr />
<h3 id="speech-codecs-are-a-balancing-act">Speech Codecs are a balancing
act</h3>
<ul>
<li><p>We want the speech to sound as ‘clear’ and ‘interpretable’ and
‘natural’ as possible</p></li>
<li><p>We want the signal to be sent using as little data as
possible</p></li>
<li><p>You cannot do both of these things at once</p></li>
<li><p>A better codec will ‘sound better’ for the same amount of
bandwidth</p></li>
<li><p>This is the “<strong>Efficiency/Quality
Tradeoff</strong>”</p></li>
</ul>
<hr />
<h3 id="perfection-is-possible-but-costly">Perfection is possible, but
costly</h3>
<ul>
<li><p>44,100 Hz 16bit WAV files will perfectly capture every detail of
human speech which matters (for 1400 kbps)</p></li>
<li><p>The median internet upload speed is 44000 kbps</p></li>
<li><p>4G cell towers max out around 100,000 kbps <strong>total</strong>
bandwidth for everybody connected to it</p>
<ul>
<li>3G towers drop down to 42,000 kbps <strong>total</strong>
bandwidth</li>
</ul></li>
<li><p>Global Satellite internet hotspots (e.g. <a
href="https://www.iridium.com/products/iridium-go-exec/">Iridium GO!
Exec</a>) have a 22 kbps uplink</p></li>
<li><p><em>Speeds are not consistent, and degrade very quickly, so we
need to compress</em></p></li>
</ul>
<hr />
<h3 id="streaming-requires-low-latency">Streaming requires low
latency</h3>
<ul>
<li><p>You can send any file over any connection if you’re willing to
wait</p></li>
<li><p>Conversations require low latency to work well</p>
<ul>
<li>Latency around 150ms is acceptable, but over 300ms is
<em>bad</em></li>
</ul></li>
<li><p><em>You need to send the data faster than you can play it back,
no matter your connection</em></p></li>
</ul>
<hr />
<h3 id="failure-is-not-an-option">Failure is not an option</h3>
<ul>
<li><p>It is much more acceptable to <em>degrade</em> a voice stream
than it is to <em>drop</em> a voice stream</p></li>
<li><p>It’s not good to say “Ah, screw it, we’ll just send the latest
chunk to catch back up and drop the stuff in the middle”</p></li>
<li><p>We can cope with a poor signal more easily than with an
inconsistent signal that cuts in and out</p></li>
<li><p>So, it’s often better to send a lower bitrate <em>just in
case</em> the signal degrades</p></li>
</ul>
<hr />
<h3 id="bitrate-options">Bitrate Options</h3>
<ul>
<li><p>Many speech codecs will offer different bitrate options</p></li>
<li><p>Options favoring quality, Options favoring compression</p></li>
<li><p>Sampling rate is also a meaningful variable</p></li>
</ul>
<hr />
<h3 id="bitrate-and-sampling-rate-selection-for-evs-in-khz">Bitrate and
Sampling Rate Selection for EVS (in kHz)</h3>
<p><img class="r-stretch" src="phonmedia/evs_bitrates.png"></p>
<hr />
<h3 id="variable-bitrates-are-also-very-possible">Variable Bitrates are
also very possible</h3>
<ul>
<li><p>“Well, we’ve got lots of bandwidth right now, so let’s increase
the quality”</p></li>
<li><p>“Uh oh, this person’s cell tower is a potato, let’s reduce the
quality”</p></li>
<li><p>“Uh, nobody’s talking on this voice call, let’s compress
<em>hard</em>”</p></li>
</ul>
<hr />
<h3 id="bitrate-is-a-choice-that-can-be-made-based-on">Bitrate is a
choice that can be made based on…</h3>
<ul>
<li><p>Network conditions</p></li>
<li><p>Service Level (e.g. ‘5G’ vs ‘4G’ vs ‘3G’)</p></li>
<li><p>Data usage</p></li>
<li><p>Dynamic Measures of Quality of Experience</p></li>
<li><p>User choice!</p></li>
</ul>
<hr />
<h3 id="regardless-of-bitrate-speech-codecs-work-the-same">Regardless of
bitrate, speech codecs work the same</h3>
<ul>
<li>Let’s talk about that!</li>
</ul>
<hr />
<h2 id="how-do-speech-codecs-work">How do Speech Codecs work?</h2>
<hr />
<h3 id="were-going-to-talk-about-three-examples">We’re going to talk
about three examples</h3>
<ul>
<li><p><strong>G.711</strong>: This is what Campus Phones and Landline
networks now use</p></li>
<li><p><strong>Enhanced Voice Services (EVS)</strong>: The next-gen,
‘5G’ codec for cell phone use</p></li>
<li><p><strong>Opus</strong>: A general purpose codec, but with a strong
speech subsystem</p></li>
</ul>
<hr />
<h3 id="g.711">G.711</h3>
<ul>
<li>This was developed in <strong>1972</strong>
<ul>
<li>OK Boomer Codec</li>
</ul></li>
<li>G.711 has an 8,000 Hz Sampling Frequency and 8 bit depth
<ul>
<li>That’s all the compression</li>
</ul></li>
<li>It uses a <a
href="https://en.wikipedia.org/wiki/Companding">companding</a> algorithm
to compress the amplitude range and expand it on the other side
<ul>
<li>Quiet parts go away, louder parts are more prominent</li>
<li>This makes 8 bit audio sound better than it has any right to</li>
</ul></li>
<li>It is <em>very simple</em>, computationally
<ul>
<li>There’s no framing, no psychoacoustics, no modeling</li>
</ul></li>
</ul>
<hr />
<h3 id="enhanced-voice-services-evs">Enhanced Voice Services (EVS)</h3>
<ul>
<li><p>Released in 2014 by <a
href="https://en.wikipedia.org/wiki/3GPP">3GPP</a>, a consortium of
standards-makers for mobile telecom</p></li>
<li><p>It offers a number of bitrates and sampling rates</p>
<ul>
<li>Lots of quality options</li>
</ul></li>
<li><p>It is heavily patent-encumbered, and requires licensing to
use</p></li>
<li><p>It uses a number of techniques to compress sound</p></li>
</ul>
<hr />
<h3 id="evs-bitrate-matrix">EVS Bitrate Matrix</h3>
<p><img class="r-stretch" src="phonmedia/evs_bitrates.png"></p>
<hr />
<h3 id="the-evs-process">The EVS Process</h3>
<ul>
<li><p>Step 1: Framing and Pre-Processing</p></li>
<li><p>Step 2: Encoding</p>
<ul>
<li>ACELP and Residual Processing AND/OR</li>
<li>MDCT Coding with Psychoacoustic Processing</li>
</ul></li>
<li><p>Step 3: Error Correction Coding and Transfer</p></li>
<li><p>Step 4: Reconstruction and Playback</p></li>
</ul>
<hr />
<h3 id="step-1-framing-and-preprocessing">Step 1: Framing and
Preprocessing</h3>
<ul>
<li><p><strong>Framing</strong>: This is 20ms</p></li>
<li><p><strong>Voice Activity Detection</strong>: Yep, same VAD we
talked about a while back</p>
<ul>
<li>If the person you’re transmitting is silent, don’t send data at all
(‘Discontinuous Transmission’)</li>
</ul></li>
<li><p><strong>Noise Removal</strong>: We covered this</p>
<ul>
<li>Wow, it’s almost like the class is arranged in a certain way for a
reason!</li>
</ul></li>
<li><p>There’s lots of other preprocessing we’re not covering…</p></li>
</ul>
<hr />
<h3 id="step-2-encoding">Step 2: Encoding</h3>
<ul>
<li><p>Now, EVS looks at the frame’s acoustics and the VAD output and
makes decisions about which encoding method(s) to use</p>
<ul>
<li><p>ACELP and Residual Processing</p></li>
<li><p>MDCT Coding</p></li>
</ul></li>
</ul>
<hr />
<h3 id="algebraic-code-excited-linear-prediction-acelp">Algebraic
code-excited linear prediction (ACELP)</h3>
<ul>
<li><p>This functions <em>exactly</em> the same as our familiar LPC when
modeling the filter</p></li>
<li><p>It models the source using a <em>codebook</em> of possible
excitation sequences</p>
<ul>
<li>Picture a dictionary of possible ways that phonation/excitation
could look</li>
<li>Don’t store the wave, store pattern ‘A’, ‘B’, ‘C’, ‘A’, ‘C’</li>
</ul></li>
<li><p>Some entries are fixed, and ‘come with the algorithm’ for use</p>
<ul>
<li>These are especially useful for noise-like or aperiodic
functions</li>
</ul></li>
</ul>
<hr />
<h3
id="algebraic-code-excited-linear-prediction-acelp-continued">Algebraic
code-excited linear prediction (ACELP) Continued</h3>
<ul>
<li>Some entries are based off patterns in prior frames
<ul>
<li>“Hey, four frames ago they did this, and now they did it again. Just
repeat that.”</li>
</ul></li>
<li>“Find combination of the filter shape and excitation type which
model the signal best”</li>
</ul>
<hr />
<h3 id="acelp-and-residual-processing">ACELP and Residual
Processing</h3>
<ul>
<li><p>We do the same thing we did with LPC in FLAC</p></li>
<li><p>Model the signal, then describe the noise that’s left
over</p></li>
<li><p>ACELP allows us to capture more of the signal cheaply, now that
it models the source too</p>
<ul>
<li>Remember that vanilla LPC leaves the source to the residuals</li>
</ul></li>
</ul>
<hr />
<h3 id="modified-discrete-cosine-transform-encoding">Modified Discrete
Cosine Transform Encoding</h3>
<ul>
<li><p>Yes, this is the same thing that we talked about for mp3</p></li>
<li><p>Use a <a
href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">Modified
Discrete Cosine Transform</a> to turn the data into coefficients
representing components in the frequency domain</p>
<ul>
<li><p>Save more, less, or no detail for chunks of the signal <em>based
on how humans perceive sound</em></p></li>
<li><p>Psychoacoustic Models are used here again to remove unimportant
sounds</p></li>
</ul></li>
<li><p><strong>This can be done on the ACELP residuals or the frame
directly</strong></p></li>
</ul>
<hr />
<h3 id="dynamic-choice-of-encoding-methods-hybrid-coding">Dynamic Choice
of Encoding Methods (‘Hybrid Coding’)</h3>
<ul>
<li><p><strong>EVS can choose which method works best for a given
frame</strong></p></li>
<li><p>For speech-heavy frames, use ACELP/Residuals</p>
<ul>
<li>That’ll compress better and give better speech results</li>
</ul></li>
<li><p>For music or other sound, use MDCT encoding <em>on the frame
directly</em></p>
<ul>
<li>That’ll better preserve non-speech spectral features, even if it
uses more bits</li>
</ul></li>
<li><p>This is chosen using a classifier based on the audio and the VAD
output</p>
<ul>
<li>This is done <strong>frame by frame</strong></li>
</ul></li>
</ul>
<hr />
<h3 id="step-3-error-correction-coding-and-transmission">Step 3: Error
Correction Coding and Transmission</h3>
<ul>
<li><p>Encode each frame in a way that allows you to detect
errors</p></li>
<li><p>Send frame information redundantly, allowing the receiver to
reconstruct any frames which were lost in transmission</p></li>
<li><p>Specialized modes exist for particularly terrible channel
conditions</p></li>
<li><p><strong>We could spend a career on error correction
methods</strong></p></li>
<li><p>Send frames bundled together, for redundancy</p></li>
</ul>
<hr />
<h3 id="step-4-reconstruction-and-playback">Step 4: Reconstruction and
Playback</h3>
<ul>
<li><p>Turn the ACELP and MDCT coded frames back into audio</p></li>
<li><p>Synthesize in high-frequency components which might have been
dropped at a given bitrate</p>
<ul>
<li>This is ‘BWR’, ‘bandwidth extension receiver’</li>
</ul></li>
<li><p>Post-Process as needed</p></li>
<li><p>Add in background noise during discontinuous transmission
gaps</p>
<ul>
<li>‘Comfort Noise Generation’ to differentiate from a dropped call</li>
</ul></li>
</ul>
<hr />
<h3 id="lets-look-at-the-whole-thing">Let’s look at the whole thing</h3>
<p><img class="r-stretch" src="phonmedia/evs_encoder.png"></p>
<hr />
<h3 id="lets-look-at-the-whole-thing-1">Let’s look at the whole
thing</h3>
<p><img class="r-stretch" src="phonmedia/evs_decoder.png"></p>
<hr />
<h3 id="you-should-understand">You should understand…</h3>
<ul>
<li><p>Why ACELP is useful and compresses better than LPC</p></li>
<li><p>Why you might want both a DCT and LPC mode for a codec</p></li>
<li><p>Why VAD is helpful in this process?</p></li>
</ul>
<hr />
<h3 id="evs-is-the-next-generation-of-cellular-audio">EVS is the next
generation of cellular audio</h3>
<ul>
<li><p>Custom designed for phone providers</p></li>
<li><p>It is a prototypical voice codec, purpose built</p></li>
<li><p>It is at the cutting edge, with <em>all</em> the
features</p></li>
</ul>
<hr />
<h3 id="opus">Opus</h3>
<ul>
<li><p>It also uses an LPC-ish speech codec (<a
href="https://en.wikipedia.org/wiki/SILK">SILK</a>) and an MDCT
encoder</p>
<ul>
<li>SILK is used for speech mode, CELT (the MDCT encoder) is used for
general audio, and there’s a hybrid mode which combines LPC and DCT for
low and high frequencies</li>
</ul></li>
<li><p>It’s completely free and open source</p></li>
<li><p>Opus is used by YouTube, WhatsApp, Signal, SoundCloud, Vimeo,
Discord, and more!</p></li>
<li><p><strong>If you need a speech (or audio) codec, Opus is currently
your best general choice</strong></p></li>
</ul>
<hr />
<h3 id="opus-speech-compression-re-waved-for-compatibility">Opus Speech
Compression (re-waved for compatibility)</h3>
<p>128kbps
<audio controls src="phonmedia/rainbow_128voice.opus.wav"></audio></p>
<p>64 kbps
<audio controls src="phonmedia/rainbow_64voice.opus.wav"></audio></p>
<p>32 kbps
<audio controls src="phonmedia/rainbow_32voice.opus.wav"></audio></p>
<p>16 kbps
<audio controls src="phonmedia/rainbow_16voice.opus.wav"></audio></p>
<p>8 kbps
<audio controls src="phonmedia/rainbow_8voice.opus.wav"></audio></p>
<p>6 kbps
<audio controls src="phonmedia/rainbow_6voice.opus.wav"></audio></p>
<hr />
<h3 id="opus-general-audio-vs.-speech-re-waved-for-compatibility">Opus
General Audio vs. Speech (re-waved for compatibility)</h3>
<p>16 kbps Audio
<audio controls src="phonmedia/rainbow_16audio.opus.wav"></audio></p>
<p>16 kbps Voice
<audio controls src="phonmedia/rainbow_16voice.opus.wav"></audio></p>
<p>8 kbps Audio
<audio controls src="phonmedia/rainbow_8audio.opus.wav"></audio></p>
<p>8 kbps Voice
<audio controls src="phonmedia/rainbow_8voice.opus.wav"></audio></p>
<p>6 kbps
Audio<audio controls src="phonmedia/rainbow_6audio.opus.wav"></audio></p>
<p>6 kbps Voice
<audio controls src="phonmedia/rainbow_6voice.opus.wav"></audio></p>
<hr />
<h3 id="mp3-vs.-opus-general-audio-vs.-opus-speech">mp3 vs. Opus General
Audio vs. Opus Speech</h3>
<p>128 kbps mp3
<audio controls src="phonmedia/nothingsomething128kbps.mp3"></audio></p>
<p>128 kbps Opus Audio
<audio controls src="phonmedia/nothingsomething128audio.opus"></audio></p>
<p>128 kbps Opus Voice
<audio controls src="phonmedia/nothingsomething128voice.opus"></audio></p>
<p>32 kbps mp3
<audio controls src="phonmedia/nothingsomething32kbps.mp3"></audio></p>
<p>32 kbps Opus Audio
<audio controls src="phonmedia/nothingsomething32audio.opus"></audio></p>
<p>32 kbps Opus Voice
<audio controls src="phonmedia/nothingsomething32voice.opus"></audio></p>
<hr />
<h3 id="mp3-vs.-opus-general-audio-vs.-opus-speech-1">mp3 vs. Opus
General Audio vs. Opus Speech</h3>
<p>8 kbps mp3
<audio controls src="phonmedia/nothingsomething8kbps.mp3"></audio></p>
<p>8 kbps Opus Audio
<audio controls src="phonmedia/nothingsomething8audio.opus"></audio></p>
<p>8 kbps Opus Voice
<audio controls src="phonmedia/nothingsomething8voice.opus"></audio></p>
<p>6 kbps Opus Audio
<audio controls src="phonmedia/nothingsomething6audio.opus"></audio></p>
<p>6 kbps Opus Voice
<audio controls src="phonmedia/nothingsomething6voice.opus"></audio></p>
<hr />
<h3 id="so-is-speech-special-for-compression">So, is speech special for
compression?</h3>
<ul>
<li><p>We get better compression when we model speech as speech</p></li>
<li><p>We get better performance when we model music as
not-speech</p></li>
<li><p>Similar methods apply, but <em>speech is different!</em></p></li>
<li><p>So, <strong>YES!</strong></p></li>
</ul>
<hr />
<h3 id="now-we-can-turn-speech-into-a-series-of-frames">Now we can turn
speech into a series of frames</h3>
<ul>
<li><p>… and we can stream those frames over any connection</p></li>
<li><p>This allows something <em>incredibly</em> valuable</p></li>
</ul>
<hr />
<h2 id="voice-encryption">Voice Encryption</h2>
<hr />
<h3
id="voices-couldnt-be-sent-without-air-for-most-of-human-history">Voices
couldn’t be sent without air for most of human history</h3>
<ul>
<li><p>Then, we could turn them into electricity send them over radio
waves</p></li>
<li><p>… but this caused a problem</p></li>
<li><p><strong>Anybody can monitor radio waves, so no communications are
private!</strong></p></li>
</ul>
<hr />
<h3
id="the-first-voice-encryption-algorithm-wasnt-computational-at-all">The
First Voice Encryption Algorithm wasn’t computational at all!</h3>
<ul>
<li><p>In WWI, WWII, Korea and Vietnam, radio encryption was not a
thing</p></li>
<li><p>This meant that anything you said into a radio, Hitler
heard.</p></li>
<li><p>This gave rise to the first method of voice encryption:
<strong>Use a language the enemies can’t understand!</strong></p></li>
</ul>
<hr />
<h3 id="code-talkers">Code Talkers</h3>
<ul>
<li><p>Speakers of obscure languages who speak their language as “code”
during war to communicate</p></li>
<li><p>Choctaw, Cherokee, Comanche, Seminole, Navajo, and Basque were
all used this way</p></li>
<li><p>Code words were used (“Turtle” for “tank”, “Gah” (“rabbit”) for
R) to further complicate things!</p></li>
<li><p>The movie “Windtalkers” is about these soldiers</p></li>
<li><p>Let’s talk about Navajo</p></li>
</ul>
<hr />
<p><danger>What features would you want a language to have if you wanted
it to be difficult for an outsider to understand?</danger></p>
<hr />
<h3 id="aside-navajo-is-a-great-code-talking-language">Aside: Navajo is
a great code-talking language</h3>
<ul>
<li><p>Lots of speakers, only in central US, no easy overseas
relatives</p></li>
<li><p>Unusual consonants, length, tone, nasality</p></li>
<li><p>Complex modality, aspect</p></li>
<li><p>Noun class and classifiers</p>
<ul>
<li>This means you often don’t need to give a noun twice!</li>
</ul></li>
<li><p>Strong synthetic morphology!</p></li>
</ul>
<hr />
<p><lang>Navajo</lang><br><ldata>Na-Dené - SW United States</ldata></p>
<iframe data-autoplay width="840" height="500" src="http://www.youtube.com/embed/XFayFUiyv20?start=20">
</iframe>
<hr />
<h3 id="this-was-actually-very-effective">This was actually very
effective!</h3>
<blockquote>
<p>At the Battle of Iwo Jima, Major Howard Connor, 5th Marine Division
signal officer, had six Navajo code talkers working around the clock
during the first two days of the battle. These six sent and received
over 800 messages, all without error. Connor later stated, “Were it not
for the Navajos, the Marines would never have taken Iwo Jima.”</p>
</blockquote>
<hr />
<h3
id="its-useful-to-be-able-to-do-this-without-two-dedicated-people">It’s
useful to be able to do this without two dedicated people</h3>
<ul>
<li>Partly because the US Government was still sending Navajo kids to
boarding schools in an attempt to kill off the language and culture
<ul>
<li>Yikes</li>
</ul></li>
</ul>
<hr />
<h3
id="is-there-a-computational-way-to-ensure-a-transmitted-message-cant-be-intercepted">Is
there a computational way to ensure a transmitted message can’t be
intercepted?</h3>
<hr />
<h3 id="voice-encryption-is-boring-now">Voice Encryption is boring
now!</h3>
<ul>
<li><p>First, you encode the signal using a voice codec</p>
<ul>
<li>This creates a stream of digtally encoded frames which you can send
over any connection</li>
</ul></li>
<li><p>The US Military has specific codecs for this, including MELPe</p>
<ul>
<li>Mixed-Excitation Linear Prediction Enhanced</li>
</ul></li>
<li><p>Then, you can just encrypt that stream!</p></li>
</ul>
<hr />
<h3 id="encryption-is-one-of-the-coolest-things-ever">Encryption is one
of the coolest things ever</h3>
<ul>
<li><p>It is several lifetimes worth of learning</p></li>
<li><p>But it involves using fancy math to obscure a series of
bytes</p></li>
</ul>
<hr />
<h3 id="encryption-algorithms-oversimplified">Encryption Algorithms
(Oversimplified)</h3>
<ul>
<li><p>‘Trap door’ functions are hard <em>only in one
direction</em></p></li>
<li><p><em>Prime Factorization</em> is a good example</p>
<ul>
<li><p>‘This number is the product of two very large prime numbers, what
are they?’</p></li>
<li><p><em>Extremely</em> expensive to calculate prime factors</p></li>
<li><p><em>Extremely</em> easy to confirm that you’ve got the correct
answer</p></li>
</ul></li>
<li><p>Your passphrase is used to generate a key which is one large
number in a trapdoor function</p>
<ul>
<li>The bits of the file are shuffled around such that they can only be
un-shuffled in the right order with the ‘key’ number in hand using an
algorithm like AES</li>
</ul></li>
</ul>
<hr />
<h3 id="the-numbers-used-are-very-large">The numbers used are very
large</h3>
<ul>
<li><p>AES-256 uses 256 bit numbers to do this math</p></li>
<li><p>115,​792,​089,​237,​316,​195,​423,​570,​985,​008,​687,​907,​853,​269,​984,​665,​640,​564,​039,​457,​584,​007,​913,​129,​639,​935
is the largest 256 bit number</p></li>
<li><p>You would need to try a <em>lot</em> of numbers (2^255 keys) to
get the answer</p>
<ul>
<li><p>If every computer on Earth worked together to crack an AES 256
key, it would take approximately
13,668,946,​519,203,305,​597,215,004,​987,461,470,​161,805,533,​714,878,481
years <a
href="https://scrambox.com/article/brute-force-aes/">(Source)</a></p></li>
<li><p>Not perfectly secure, but damned close</p></li>
</ul></li>
</ul>
<hr />
<h3 id="you-can-stream-encrypted-data">You can stream encrypted
data</h3>
<ul>
<li><p>Exchange keys with the other party, somehow</p></li>
<li><p>Encrypt each frame (or packet of frames) along with a
counter</p></li>
<li><p>Send frames as they’re generated</p></li>
<li><p>The receiver decrypts frames as they arrive, ensuring that the
counter matches</p></li>
<li><p><em>This is the world’s worst explanation of AES Streaming using
GCM</em></p></li>
</ul>
<hr />
<h3 id="now-we-can-send-encrypted-voice-packets">Now, we can send
encrypted voice packets</h3>
<ul>
<li><p>In a way that is (basically) impossible to read without the
key</p></li>
<li><p>This is excellent for military communications</p></li>
<li><p>This is becoming common for police departments</p>
<ul>
<li>There are questions to be asked about this</li>
</ul></li>
<li><p>It takes some extra processing, but it’s shockingly fast and
efficient on modern machines!</p></li>
</ul>
<hr />
<h3 id="wrapping-up">Wrapping up</h3>
<ul>
<li><p>Speech may be special</p>
<ul>
<li>… and certainly is for compression!</li>
</ul></li>
<li><p>Speech codecs allow us to send voices over tiny
bandwidths</p></li>
<li><p>Bitrate is hugely important, and the quality/efficiency tradeoff
is difficult</p></li>
<li><p>Speech Codecs usually work using some flavor of LPC</p>
<ul>
<li>… and good ones offer some additional DCT-based approach too for
non-speech information</li>
</ul></li>
<li><p>Voice encryption just uses a speech codec, and then encrypts the
output</p></li>
</ul>
<hr />
<h3 id="next-time">Next time</h3>
<ul>
<li>So, what are we doing with all these files, anyways?</li>
</ul>
<hr />
<p><huge>Thank you!</huge></p>
</body>
</html>
