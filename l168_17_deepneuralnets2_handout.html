<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title></title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <style type="text/css">
  /*
   * I add this to html files generated with pandoc.
   * Originally from https://gist.github.com/killercup/5917178
   */

  html {
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
  }

  body {
      color: #444;
      font-family: "Source Sans 3", Helvetica-Neue, Helvetica, Sans;
      line-height: 1.5;
      padding: 0.5em;
      margin: auto;
      max-width: 55em;
      background: #fefefe;
  }

  a {
      color: #2171b5;
      text-decoration: underline;
  }

  tr:nth-child(even) {background: #F8F8F8}
  tr:nth-child(odd) {background: #FFF}

  a:visited {
      color: #2171b5;
      text-decoration: none;
  }

  a:focus {
      outline: thin dotted;
  }

  *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  p {
      margin: 0.75em 0;
  }

  img {
      max-width: 60%;
      max-height:400px;
  }

  video {
      max-width: 60%;
  }


  h1, h2, h3, h4, h5, h6 {
      color: #111;
      line-height: 80%;
      margin-top: 1em;
      margin-bottom: 0.5em;
      font-weight: normal;
  }

  h1, h2, h3, h4, h5, h6 {
      font-weight: bold;
  }

  h1 {
      font-size: 2em;
      line-height: 1.25;
      color:  #084594;

  }

  h1.title {
      margin-top:0.2em;
      font-size: 2em;
      line-height: 1.25;
  }

  h2 {
      font-size: 1.5em;
      line-height: 1.6em;
          color:  #084594;
      padding-bottom: 3px;

  }

  h3 {
      font-size: 1.2em;
      line-height: 1.6em;
  }


  h4 {
      font-size: 1.2em;
      line-height: 1.4em;
  }

  h5 {
      font-size: 1em;
  }

  h6 {
      font-size: 0.9em;
  }

  blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #EEE solid;
  }

  hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 0.5em 0;
      padding: 0;
  }

  pre, code, kbd, samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: 'courier new', monospace;
      font-size: 0.98em;
  }

  pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
  }

  .answer {
      color:#CC0033;
      font-style:italic;
  }

  b, strong {
      font-weight: bold;
  }

  dfn {
      font-style: italic;
  }

  ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
  }

  mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
  }

  sub, sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
  }

  sup {
      top: -0.5em;
  }

  sub {
      bottom: -0.25em;
  }

  ul, ol {
      margin: 0.5em 0;
      padding: 0em 0em 0em 1em;
  }

  ul img {
      list-style-type: none;
  }

  li p:last-child {
      margin-bottom: 0;
  }

  hr {
      border-top:none;
      height:0px;
      clear:both;
  }

  ul ul, ol ol {
      margin: .3em 0;
  }

  dl {
      margin-bottom: 1em;
  }

  dt {
      font-weight: bold;
      margin-bottom: .8em;
  }

  dd {
      margin: 0 0 .8em 2em;
  }

  dd:last-child {
      margin-bottom: 0;
  }

  img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
  }

  figure {
      display: block;
      text-align: center;
      margin: 1em 0;
  }

  figure img {
      border: none;
      margin: 0 auto;
  }

  figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 .8em;
  }

  table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
  }

  table th {
      padding: .2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
  }

  table td {
      padding: .2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
  }

  .author {
      font-size: 1.2em;
      text-align: center;
  }

  @media only screen and (min-width: 480px) {
      body {
  	font-size: 14px;
      }
  }
  @media only screen and (min-width: 768px) {
      body {
  	font-size: 16px;
      }
  }
  @media print {
      * {
  	background: transparent !important;
  	color: black !important;
  	filter: none !important;
  	-ms-filter: none !important;
      }

      body {
  	font-size: 12pt;
  	max-width: 100%;
      }

      a, a:visited {
  	text-decoration: underline;
      }

      hr {
  	height: 1px;
  	border: 0;
  	border-bottom: 1px solid black;
      }

      a[href]:after {
  	content: " (" attr(href) ")";
      }

      abbr[title]:after {
  	content: " (" attr(title) ")";
      }

      .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
  	content: "";
      }

      pre, blockquote {
  	border: 1px solid #999;
  	padding-right: 1em;
  	page-break-inside: avoid;
      }

      tr, img {
  	page-break-inside: avoid;
      }

      img {
  	max-width: 40% !important;
      max-height: 300px !important;
      }

      @page :left {
  	margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
  	margin: 15mm 10mm 15mm 20mm;
      }

      p, h2, h3 {
  	orphans: 3;
  	widows: 3;
      }

      h2, h3 {
  	page-break-after: avoid;
      }
  }


  ldata {
  	font-size: 0.7em;
  	margin-bottom: 0em;
  	color:#808080;
  	font-style:italic;
  }

  danger {
  	color:#FF0000;
  	font-weight:bold;
  }

  correct {
  	color:#39C900;
  	font-weight:bold;
  }

  clg{
      color:#39C900;
  	font-weight:bold;
  }

  clr{
  	color:#FF0000;
  	font-weight:bold;
  }

  clb{
  	color:#0000CC;
  	font-weight:bold;
  }

  clp{
  	color:#6600FF;
  	font-weight:bold;
  }

  clk{
  	color:#708cef;
  	font-weight:bold;
  }

  clo{
  	color:#CC6600;
  	font-weight:bold;
  }

  sc{
          font-variant: small-caps;
  }

  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1
id="deep-neural-networks-ii-awfulness-advantages-and-architectures">Deep
Neural Networks II: Awfulness, Advantages, and Architectures</h1>
<h3 id="will-styler---lign-168">Will Styler - LIGN 168</h3>
<hr />
<h3
id="last-time-we-talked-about-the-core-ideas-of-deep-neural-networks">Last
time, we talked about the core ideas of Deep Neural Networks</h3>
<hr />
<h3 id="neural-network-review">Neural Network Review</h3>
<ul>
<li><p>Artificial Neurons turn inputs into outputs according to function
and bias, and output according to weights</p></li>
<li><p>Deep Neural Networks allow more complex decision making</p></li>
<li><p>Training involves doing inference, finding error, assigning that
error to individual weights/biases, and updating parameters</p></li>
<li><p>Inference is just putting the input in, and observing the
outputs</p></li>
</ul>
<hr />
<h3 id="today-well-go-a-bit-deeper">Today, we’ll go a bit… deeper</h3>
<ul>
<li><p>We know they’re unreasonably powerful</p></li>
<li><p>It’s not all good, though</p></li>
<li><p>… and they’re not just one model</p></li>
</ul>
<hr />
<h3 id="todays-plan">Today’s Plan</h3>
<ul>
<li><p>What are the problems with using Deep Neural Networks?</p></li>
<li><p>What are the advantages of Deep Neural Networks?</p></li>
<li><p>Convolutional Neural Networks</p></li>
<li><p>Sequence Modeling and Transformers</p></li>
</ul>
<hr />
<h2 id="deep-neural-network-downsides">Deep Neural Network
Downsides</h2>
<hr />
<h3 id="tanstaafl">TANSTAAFL</h3>
<ul>
<li><p>Neural Networks are amazing, but they are not perfect</p></li>
<li><p>Let’s talk about why!</p></li>
</ul>
<hr />
<h3 id="opacity">Opacity</h3>
<ul>
<li><p>Neural models do not reveal their features, nor their decision
making</p>
<ul>
<li>We get <em>no</em> useful information from a trained model except
output</li>
</ul></li>
<li><p>We as a species do not understand how they’re actually doing the
task</p></li>
<li><p>Being able to understand decisions in DNNs is an active area of
research</p>
<ul>
<li>… and a great way to get every prize in CS, Math, and Cognitive
Science</li>
</ul></li>
</ul>
<hr />
<h3 id="alignment-questions">Alignment Questions</h3>
<ul>
<li><p>If we don’t know how it’s making a decision, we can’t know
whether it’s doing ‘the right thing’</p></li>
<li><p>There’s the possibility of unclear ‘why’</p>
<ul>
<li>Is this just rejecting mortgage applications based on the person’s
Facebook Friends’ first names?</li>
<li>Is the tax audit selection model deprioritizing owners of Rolls
Royce cars for audits because it learned they tend to face less
scrutiny?</li>
</ul></li>
<li><p>This is a key component of ‘AI Safety’ as discussed
today</p></li>
</ul>
<hr />
<h3 id="bias">Bias</h3>
<ul>
<li>Neural models learn the same patterns humans do
<ul>
<li>When you give a model the entire internet, you get back a
racist</li>
</ul></li>
<li>If we can’t control the model, we can’t ‘counterbalance’ bias
<ul>
<li>Attempts often go poorly (e.g. <a
href="https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical">Gemini
Image Generator producing Black and Asian Nazi Soldiers</a>)</li>
</ul></li>
<li>Your training data dictates the performance
<ul>
<li>If you don’t include Nigerian English, it won’t work well for
Nigerian English</li>
</ul></li>
</ul>
<hr />
<h3 id="dual-use-problems">Dual Use Problems</h3>
<ul>
<li><p>Models can be used for great good, or great evil</p>
<ul>
<li><p>“Allow people with mobility to type” and ‘Allow all phone calls,
period, to be transcribed’</p></li>
<li><p>Many beneficial tasks are very similar to very unethical
tasks</p></li>
</ul></li>
<li><p>It is not possible to control what humans do with this
tool</p></li>
<li><p>We cannot readily control people’s ability to use or make these
models (unlike e.g. plutonium)</p></li>
</ul>
<hr />
<h3 id="data-requirements">Data Requirements</h3>
<ul>
<li>Training Neural models requires large amounts of high quality data
<ul>
<li>“Data! Data! Data! Everything else is bullshit!”</li>
</ul></li>
<li>Increasingly, people are trying to restrict previously public data
<ul>
<li>Content Cartels are especially trying to restrict the use of their
work for training</li>
</ul></li>
<li>Some languages may not have large amounts of extant (speech) data
<ul>
<li>Equity problems? In AI and tech?! That’s unpossible!</li>
</ul></li>
</ul>
<hr />
<h3 id="specialized-hardware-requirements">Specialized Hardware
Requirements</h3>
<ul>
<li><p>Neural Networks don’t work well on normal consumer
computers</p></li>
<li><p>Graphics Processing Units (GPUs) used for rendering graphics turn
out to be great at other matrix multiplication, too</p>
<ul>
<li>DNNs tend to require large amounts of VRAM (video memory)</li>
</ul></li>
<li><p>Desktop Workstations designed for this task cost upwards of
$150,000</p>
<ul>
<li>Even a single top-of-the-line GPU (Nvidia H100) can be $30,000+</li>
</ul></li>
<li><p>Nvidia has a near-monopoly at the moment, in hardware and
software</p>
<ul>
<li>When you design your process around one company’s software, you
suffer!</li>
</ul></li>
</ul>
<hr />
<h3 id="energy-use">Energy Use</h3>
<ul>
<li>Neural Networks are incredibly energy intensive to train and use
<ul>
<li><a href="https://arxiv.org/pdf/1906.02243">One credible source from
2019</a></li>
<li>Assume that in 2024, it’s wildly worse</li>
</ul></li>
<li>There is a movement for ‘green AI’, but it’s slow and up against
legions of shareholders</li>
</ul>
<hr />
<p><img class="r-stretch" src="img/nn_carbonfootprint.png"></p>
<hr />
<h3 id="expensive-slow-training">Expensive, Slow training</h3>
<ul>
<li><p>These models train slowly, even on top of the line
hardware</p></li>
<li><p>Energy costs are very high</p></li>
<li><p>Creating a model often requires creating several models to find
best parameter sets</p>
<ul>
<li>‘Grid Search’ is wildly expensive</li>
</ul></li>
<li><p>Many languages around the world currently lack the fiscal and
energy resources to train ChatGPT-level LLMs</p></li>
</ul>
<hr />
<h3 id="gatekeeping">Gatekeeping</h3>
<ul>
<li><p>Hardware, energy use, and slow training makes these models easier
to keep behind paywalls</p></li>
<li><p>Increasing pushes from the industry to use regulation to ensure
only they can deploy these models</p></li>
<li><p>Open source/weight models are competitive, but still impossible
for most people to run at home</p></li>
</ul>
<hr />
<h3 id="brittlenesss">Brittlenesss</h3>
<ul>
<li>Neural Models tend to fail interestingly, and not like humans
<ul>
<li>Repeating words or phrases</li>
<li>Guessing low-frequency items that ‘don’t make any sense’</li>
</ul></li>
<li>Different voices may perform wildly worse
<ul>
<li>Dialect, age, vocal pathologies, etc</li>
</ul></li>
</ul>
<hr />
<h3 id="adversarial-attacks">Adversarial Attacks</h3>
<ul>
<li><p>People with knowledge of the model can subvert it in interesting
ways</p></li>
<li><p>Stimuli which are perfectly acceptable to humans can be wildly
misclassified</p></li>
<li><p><a href="https://arxiv.org/pdf/1707.08945">Stop Signs can be
turned into 45mpg signs</a></p></li>
<li><p><a
href="https://deepmind.google/discover/blog/images-altered-to-trick-machine-vision-can-influence-humans-too/">Some
of these attacks work on humans, too</a></p></li>
</ul>
<hr />
<p><img class="r-stretch" src="img/nn_adversarial.png"></p>
<hr />
<h3 id="but-its-not-all-bad">… but, it’s not all bad!</h3>
<hr />
<h2 id="deep-neural-network-advantages">Deep Neural Network
Advantages</h2>
<hr />
<h3 id="dnns-have-won-many-tasks-in-nlp-and-ml">DNNs have ‘won’ many
tasks in NLP and ML</h3>
<ul>
<li>… but why?</li>
</ul>
<hr />
<h3 id="end-to-end-processing">End-to-End Processing</h3>
<ul>
<li><p>We don’t need to spend time thinking about features, just data
and loss</p></li>
<li><p>This is the first kind of model which we’ve discovered which does
this and works well</p></li>
<li><p><strong>This alone is enough to make DNNs very, very
competitive</strong></p></li>
</ul>
<hr />
<h3 id="non-linearity">Non-Linearity</h3>
<ul>
<li><p>The patterns you find don’t need to be remotely linear, unlike
many classical approaches</p></li>
<li><p>You can model any continuous function with a neuron count that’s
sufficiently high</p>
<ul>
<li>This is the ‘Universal Approximation Theorem’</li>
</ul></li>
<li><p>You can use <em>regularization</em> to help reduce or prevent
overfitting</p></li>
</ul>
<hr />
<h3 id="transfer-learning">Transfer Learning</h3>
<ul>
<li><p>Neural Networks can be trained on a more general task
(e.g. recognizing speech) and then used on a more specific one
(e.g. recognizing Afrikaans)</p></li>
<li><p>Fine-tuning can be helpful to improve performance with
out-of-dataset tasks</p></li>
<li><p>Not every problem needs a Whole New Model</p></li>
</ul>
<hr />
<h3 id="scalability">Scalability</h3>
<ul>
<li><p>Often, more parameters is more better</p></li>
<li><p>Wav2vec2 has 317 million parameters</p></li>
<li><p>ChatGPT 3.5 is suspected to have ~20 billion parameters</p></li>
<li><p>Anthropic’s Claude 3 has a rumored 500 billion
parameters</p></li>
</ul>
<hr />
<h3 id="structural-flexibility">Structural Flexibility</h3>
<ul>
<li><p>You can scale DNNs very readily, from small to large</p></li>
<li><p>You can design neural networks with many specialized
<em>architectures</em>, that is, arrangements of neurons and
units</p></li>
<li><p>DNN architectures can be <em>task specific</em>, and improve
performance markedly</p></li>
<li><p>This leads to…</p></li>
</ul>
<hr />
<h2 id="neural-architectures">Neural Architectures</h2>
<hr />
<h3 id="not-every-model-is-so-simple">Not every model is so simple</h3>
<p><img class="r-stretch" src="img/dnn.jpg"></p>
<hr />
<h3 id="weve-been-talking-about-fnns">We’ve been talking about FNNs</h3>
<ul>
<li><p>‘Feedforward Neural Networks’</p></li>
<li><p>We’ve also been focused on ‘fully connected’ or ‘dense’
networks</p></li>
<li><p><strong>But there are many other approaches!</strong></p>
<ul>
<li>… and we’re going to touch on a few of them</li>
</ul></li>
</ul>
<hr />
<h3 id="sometimes-you-want-more-than-one-model">Sometimes, you want more
than one model</h3>
<ul>
<li><p>This can happen with encoder-decoder models</p></li>
<li><p>… or with…</p></li>
</ul>
<hr />
<h3 id="gans-generative-adversarial-networks">GANs (Generative
Adversarial Networks)</h3>
<ul>
<li><p>Often used for generating images or any other kind of
‘imitation’</p>
<ul>
<li><a href="https://thispersondoesnotexist.com/"
class="uri">https://thispersondoesnotexist.com/</a></li>
</ul></li>
<li><p>Also used for denoising audio (‘imitate the original audio
without noise’)</p></li>
<li><p>Make one model which generates a thing, and another which tries
to detect generated things</p>
<ul>
<li>Training is a cat-and-mouse game</li>
</ul></li>
</ul>
<hr />
<p><img class="r-stretch" src="img/nn_gan.jpg"></p>
<hr />
<h3 id="another-sort-of-two-model-model-is-an-autoencoder">Another sort
of ‘two model’ model is an ‘autoencoder’</h3>
<ul>
<li><p>One model generates representations of the input data</p></li>
<li><p>Another model takes those representations and decodes them into a
different form</p></li>
<li><p>More later!</p></li>
</ul>
<hr />
<h3 id="what-if-you-want-to-classify-rather-than-create">What if you
want to classify, rather than create?</h3>
<hr />
<h2 id="convolutional-neural-networks">Convolutional Neural
Networks</h2>
<hr />
<h3 id="convolutional-neural-networks-cnns">Convolutional Neural
Networks (CNNs)</h3>
<ul>
<li><p>Primarily used for processing grid-like data (e.g., images,
spectrograms)</p></li>
<li><p>Excel in capturing spatial hierarchies in data.</p></li>
<li><p>Commonly applied in image and video recognition, image
classification, medical image analysis</p></li>
</ul>
<hr />
<h3 id="cnn-layers-arent-all-made-equal">CNN Layers aren’t all made
equal</h3>
<ul>
<li>Fully Connected (Dense) Layers
<ul>
<li>We’ve already seen these!</li>
</ul></li>
<li>Convolutional Layers
<ul>
<li>These do very explicit feature-finding, identifying repeating
patterns</li>
</ul></li>
<li>Pooling Layers
<ul>
<li>These effectively compress the data, passing through only the most
important data</li>
</ul></li>
</ul>
<hr />
<h3 id="convolutional-layers">Convolutional Layers</h3>
<ul>
<li><p>Each filter is a small matrix used to detect specific features
(e.g., edges, textures)</p>
<ul>
<li>Convolution operation slides the filter over the input and computes
the dot product at each position
<ul>
<li>“How much does the filter ‘fit’ when placed here? And here? And
here?”</li>
</ul></li>
</ul></li>
<li><p>Resulting feature map highlights areas of high similarity to the
filter</p></li>
</ul>
<hr />
<p><img class="r-stretch" src="img/nn_convfilter.jpg"></p>
<hr />
<h3 id="filters-highlight-different-aspects-of-the-image">Filters
highlight different aspects of the image</h3>
<p><img class="r-stretch" src="img/nn_conv_features.jpg"></p>
<hr />
<h3 id="pooling-layers">Pooling Layers</h3>
<ul>
<li><p>Reduces the dimensionality of the prior layer, but retains the
most important information</p>
<ul>
<li>Sort of like DCT compression conceptually, although very different
in practice</li>
</ul></li>
<li><p><strong>Max Pooling</strong> keeps the largest number and its
position from the prior layer</p></li>
<li><p><strong>Mean pooling</strong> keeps the average number from the
prior layer</p></li>
</ul>
<hr />
<p><img class="r-stretch" src="img/nn_conv_meanmaxpool.jpg"></p>
<hr />
<h3
id="pooling-layers-reduce-complexity-while-preserving-important-stuff">Pooling
Layers reduce complexity, while preserving important stuff</h3>
<p><img class="r-stretch" src="img/nn_conv_shrinking.jpg"></p>
<hr />
<h3 id="eventually-youd-feed-it-into-a-normal-fnn">Eventually you’d feed
it into a normal FNN</h3>
<p><img class="r-stretch" src="img/nn_conv_fullpath.jpg"></p>
<hr />
<h3 id="you-can-even-get-fancier">You can even get fancier!</h3>
<p><img class="r-stretch" src="img/nn_conv_zhuetal.png"></p>
<hr />
<h3 id="cnns-excel-at-finding-patterns-in-grid-like-data">CNNs excel at
finding patterns in grid-like data</h3>
<ul>
<li><p>They concentrate data into meaningful patterns</p></li>
<li><p>They toss away less meaningful data</p></li>
<li><p>They feed it into a regular neural network for
classification</p></li>
<li><p>You can find the important elements, <em>no matter where they
occur in the grid</em></p></li>
</ul>
<hr />
<h3 id="but-some-kinds-of-data-arent-grids-theyre-sequences">… but some
kinds of data aren’t grids, they’re sequences</h3>
<ul>
<li>For that, we need…</li>
</ul>
<hr />
<h2 id="sequence-modeling-and-transformers">Sequence Modeling and
Transformers</h2>
<p><img class="r-stretch" src="img/soundwave.jpg"></p>
<hr />
<h3 id="what-if-your-input-is-a-sequence-of-things">What if your input
is a sequence of things?</h3>
<ul>
<li><p>Sequences of numbers (e.g. time series data)</p></li>
<li><p>Sequences of categories (e.g. different phonemes)</p></li>
<li><p>Sequences of words (e.g. sentences, books)</p></li>
</ul>
<hr />
<h3 id="rnns-recurrent-neural-networks">RNNs (Recurrent Neural
Networks)</h3>
<ul>
<li><p>Tuned for data which are sequential</p></li>
<li><p>These include a short term memory, so that the output of each
neuron is also influenced by the <em>prior</em> output</p></li>
<li><p>LSTM (Long Short Term Memory) networks are a variant allow for
increased memory</p></li>
<li><p><strong>These have been largely supplanted by…</strong></p></li>
</ul>
<hr />
<h3 id="transformers">Transformers</h3>
<ul>
<li><p>Developed by Vaswani et al. (2017) in the paper “Attention is All
You Need”</p></li>
<li><p>Excels in understanding context and relationships in text (and
other sequential data)</p>
<ul>
<li>They are winning many sequence-based ML tasks!</li>
</ul></li>
<li><p>Two Core Innovations</p>
<ul>
<li>Self-Attention Mechanism</li>
<li>Positional Encoding</li>
</ul></li>
</ul>
<hr />
<h3 id="self-attention">Self-Attention</h3>
<ul>
<li><p>Allows the model to weigh the importance of words in a sentence
(e.g), ignoring their position</p></li>
<li><p>Each input word is transformed into a Query (Q) and Key (K),
which are turned into a by-word value</p></li>
<li><p>This is done several times in parallel (‘multi-headed
attention’), with each calculation finding different elements</p></li>
<li><p>Output is a weighted sum of values, focusing the model’s
attention on important words</p></li>
</ul>
<hr />
<h3 id="positional-encoding">Positional Encoding</h3>
<ul>
<li><p>Rather than using serial processing (like RNN/LSTM), positional
encodings are added to tokens to ‘save’ word positions</p>
<ul>
<li>This is done using a fancy sine/cosine pattern embedding</li>
</ul></li>
<li><p>This, with attention (which is handled by matrices), allow you to
process the entire input at once, rather than running through
sequentially!</p></li>
<li><p><strong>Transformers process the entire input at
once!</strong></p>
<ul>
<li>This makes for much more efficient training</li>
</ul></li>
</ul>
<hr />
<h3 id="this-is-part-of-why-transformers-are-so-dominant">This is part
of why transformers are so dominant!</h3>
<ul>
<li><p>They handle very long context lengths, allowing long-distance
dependencies (e.g. between ‘they’ and ‘transformers’)</p></li>
<li><p>They scale well, with more parameters able to be added for better
performance</p></li>
<li><p>Attention allows focus on the most important relationships in the
context</p></li>
<li><p>You can look at <em>massive</em> context lengths, so you can
interpret massive texts and questions.</p></li>
<li><p>They’re very flexible, working in a lot of domains</p></li>
</ul>
<hr />
<h3 id="they-do-have-disadvantages">They do have disadvantages</h3>
<ul>
<li><p>They need a lot of computing and memory</p>
<ul>
<li>Self Attention scales quadratically with context length</li>
</ul></li>
<li><p>They need <em>massive</em> amounts of data to train</p></li>
<li><p>They’re unreasonably good, so large numbers of tasks just become
“uh, throw it into a transformer”</p></li>
</ul>
<hr />
<h3 id="autoencoder-structure">‘Autoencoder’ Structure</h3>
<p><img class="r-stretch" src="img/nn_transformer.jpg"></p>
<hr />
<h3 id="were-going-to-see-a-lot-of-autoencoders">We’re going to see a
lot of autoencoders!</h3>
<ul>
<li><p>“Build a representation using one chunk of the network, then
interpret it using another chunk”</p></li>
<li><p>These are really good for changing one kind of data into
another</p>
<ul>
<li>Like, I don’t know, speech into text</li>
</ul></li>
</ul>
<hr />
<h3 id="transformers-are-complicated">Transformers are complicated</h3>
<ul>
<li><p>We could spend a quarter to understand every element</p></li>
<li><p>LIGN 167 goes much deeper into how they work</p></li>
<li><p>For now, you know enough to roughly understand the methods we use
for…</p></li>
</ul>
<hr />
<h3 id="neural-automatic-speech-recogntion">Neural Automatic Speech
Recogntion!</h3>
<ul>
<li>Next time!</li>
</ul>
<hr />
<h3 id="wrapping-up">Wrapping up</h3>
<ul>
<li><p>Deep Neural Networks have lots of problems</p></li>
<li><p>Deep Neural Networks are also unreasonably effective</p></li>
<li><p>Convolutional Networks are great for grid-based data</p></li>
<li><p>Transformers are great for sequence data</p></li>
<li><p>All of this is relevant for speech!</p></li>
</ul>
<hr />
<p><huge>Thank you!</huge></p>
</body>
</html>
