<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title></title>
  <style>
    html {
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 12px;
      }
      h1 {
        font-size: 1.8em;
      }
    }
    @media print {
      html {
        background-color: white;
      }
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, Consolas, 'Lucida Console', monospace;
      font-size: 85%;
      margin: 0;
      hyphens: manual;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC ul {
      padding-left: 1.3em;
    }
    #TOC > ul {
      padding-left: 0;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <style type="text/css">
  /*
   * I add this to html files generated with pandoc.
   * Originally from https://gist.github.com/killercup/5917178
   */

  html {
      overflow-y: scroll;
      -webkit-text-size-adjust: 100%;
      -ms-text-size-adjust: 100%;
  }

  body {
      color: #444;
      font-family: "Source Sans 3", Helvetica-Neue, Helvetica, Sans;
      line-height: 1.5;
      padding: 0.5em;
      margin: auto;
      max-width: 55em;
      background: #fefefe;
  }

  a {
      color: #2171b5;
      text-decoration: underline;
  }

  tr:nth-child(even) {background: #F8F8F8}
  tr:nth-child(odd) {background: #FFF}

  a:visited {
      color: #2171b5;
      text-decoration: none;
  }

  a:focus {
      outline: thin dotted;
  }

  *::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  *::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #000;
  }

  a::-moz-selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  a::selection {
      background: rgba(255, 255, 0, 0.3);
      color: #0645ad;
  }

  p {
      margin: 0.75em 0;
  }

  img {
      max-width: 60%;
      max-height:400px;
  }

  video {
      max-width: 60%;
  }


  h1, h2, h3, h4, h5, h6 {
      color: #111;
      line-height: 80%;
      margin-top: 1em;
      margin-bottom: 0.5em;
      font-weight: normal;
  }

  h1, h2, h3, h4, h5, h6 {
      font-weight: bold;
  }

  h1 {
      font-size: 2em;
      line-height: 1.25;
      color:  #084594;

  }

  h1.title {
      margin-top:0.2em;
      font-size: 2em;
      line-height: 1.25;
  }

  h2 {
      font-size: 1.5em;
      line-height: 1.6em;
          color:  #084594;
      padding-bottom: 3px;

  }

  h3 {
      font-size: 1.2em;
      line-height: 1.6em;
  }


  h4 {
      font-size: 1.2em;
      line-height: 1.4em;
  }

  h5 {
      font-size: 1em;
  }

  h6 {
      font-size: 0.9em;
  }

  blockquote {
      color: #666666;
      margin: 0;
      padding-left: 3em;
      border-left: 0.5em #EEE solid;
  }

  hr {
      display: block;
      height: 2px;
      border: 0;
      border-top: 1px solid #aaa;
      border-bottom: 1px solid #eee;
      margin: 0.5em 0;
      padding: 0;
  }

  pre, code, kbd, samp {
      color: #000;
      font-family: monospace, monospace;
      _font-family: 'courier new', monospace;
      font-size: 0.98em;
  }

  pre {
      white-space: pre;
      white-space: pre-wrap;
      word-wrap: break-word;
  }

  .answer {
      color:#CC0033;
      font-style:italic;
  }

  b, strong {
      font-weight: bold;
  }

  dfn {
      font-style: italic;
  }

  ins {
      background: #ff9;
      color: #000;
      text-decoration: none;
  }

  mark {
      background: #ff0;
      color: #000;
      font-style: italic;
      font-weight: bold;
  }

  sub, sup {
      font-size: 75%;
      line-height: 0;
      position: relative;
      vertical-align: baseline;
  }

  sup {
      top: -0.5em;
  }

  sub {
      bottom: -0.25em;
  }

  ul, ol {
      margin: 0.5em 0;
      padding: 0em 0em 0em 1em;
  }

  ul img {
      list-style-type: none;
  }

  li p:last-child {
      margin-bottom: 0;
  }

  hr {
      border-top:none;
      height:0px;
      clear:both;
  }

  ul ul, ol ol {
      margin: .3em 0;
  }

  dl {
      margin-bottom: 1em;
  }

  dt {
      font-weight: bold;
      margin-bottom: .8em;
  }

  dd {
      margin: 0 0 .8em 2em;
  }

  dd:last-child {
      margin-bottom: 0;
  }

  img {
      border: 0;
      -ms-interpolation-mode: bicubic;
      vertical-align: middle;
  }

  figure {
      display: block;
      text-align: center;
      margin: 1em 0;
  }

  figure img {
      border: none;
      margin: 0 auto;
  }

  figcaption {
      font-size: 0.8em;
      font-style: italic;
      margin: 0 0 .8em;
  }

  table {
      margin-bottom: 2em;
      border-bottom: 1px solid #ddd;
      border-right: 1px solid #ddd;
      border-spacing: 0;
      border-collapse: collapse;
  }

  table th {
      padding: .2em 1em;
      background-color: #eee;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
  }

  table td {
      padding: .2em 1em;
      border-top: 1px solid #ddd;
      border-left: 1px solid #ddd;
      vertical-align: top;
  }

  .author {
      font-size: 1.2em;
      text-align: center;
  }

  @media only screen and (min-width: 480px) {
      body {
  	font-size: 14px;
      }
  }
  @media only screen and (min-width: 768px) {
      body {
  	font-size: 16px;
      }
  }
  @media print {
      * {
  	background: transparent !important;
  	color: black !important;
  	filter: none !important;
  	-ms-filter: none !important;
      }

      body {
  	font-size: 12pt;
  	max-width: 100%;
      }

      a, a:visited {
  	text-decoration: underline;
      }

      hr {
  	height: 1px;
  	border: 0;
  	border-bottom: 1px solid black;
      }

      a[href]:after {
  	content: " (" attr(href) ")";
      }

      abbr[title]:after {
  	content: " (" attr(title) ")";
      }

      .ir a:after, a[href^="javascript:"]:after, a[href^="#"]:after {
  	content: "";
      }

      pre, blockquote {
  	border: 1px solid #999;
  	padding-right: 1em;
  	page-break-inside: avoid;
      }

      tr, img {
  	page-break-inside: avoid;
      }

      img {
  	max-width: 40% !important;
      max-height: 300px !important;
      }

      @page :left {
  	margin: 15mm 20mm 15mm 10mm;
      }

      @page :right {
  	margin: 15mm 10mm 15mm 20mm;
      }

      p, h2, h3 {
  	orphans: 3;
  	widows: 3;
      }

      h2, h3 {
  	page-break-after: avoid;
      }
  }


  ldata {
  	font-size: 0.7em;
  	margin-bottom: 0em;
  	color:#808080;
  	font-style:italic;
  }

  danger {
  	color:#FF0000;
  	font-weight:bold;
  }

  correct {
  	color:#39C900;
  	font-weight:bold;
  }

  clg{
      color:#39C900;
  	font-weight:bold;
  }

  clr{
  	color:#FF0000;
  	font-weight:bold;
  }

  clb{
  	color:#0000CC;
  	font-weight:bold;
  }

  clp{
  	color:#6600FF;
  	font-weight:bold;
  }

  clk{
  	color:#708cef;
  	font-weight:bold;
  }

  clo{
  	color:#CC6600;
  	font-weight:bold;
  }

  sc{
          font-variant: small-caps;
  }

  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<p><img class="big" src="ling_memes/vowelspace.jpg"></p>
<hr />
<h1 id="vowel-perception-and-speaker-normalization">Vowel Perception and
Speaker Normalization</h1>
<p><img class="small" src="phonmedia/vowelformants.gif"></p>
<h3 id="will-styler">Will Styler</h3>
<hr />
<h1 id="vowel-perception-is-basically-magic">Vowel Perception is
Basically Magic</h1>
<p><img class="small" src="img/hogwarts.jpg"></p>
<h3 id="will-styler-1">Will Styler</h3>
<hr />
<p><img class="big" src="phonmedia/ipa_vowels.png"></p>
<hr />
<h3 id="review-what-is-a-vowel">Review: What is a vowel?</h3>
<ul>
<li><p>A vowel is voicing passing through (and resonating in) an
unobstructed vocal tract!</p></li>
<li><p>If we change the position of the tongue, we change the
resonances</p></li>
</ul>
<hr />
<p><img class="big" src="phonmedia/voweltongue.png"></p>
<hr />
<h3 id="review-what-is-a-vowel-1">Review: What is a vowel?</h3>
<p>A vowel is voicing passing through (and resonating in) an
unobstructed vocal tract!</p>
<p>If we change the position of the tongue, we change the resonances</p>
<ul>
<li><p>Different resonances <em>filter</em> the sound differently and
determine the vowel quality</p></li>
<li><p><strong>Different tongue shapes create different resonances, and
different vowels!</strong></p></li>
</ul>
<hr />
<p><img class="big" src="phonmedia/voweltongue2.png"></p>
<hr />
<h3 id="what-do-vowels-sound-like">What do vowels sound like?</h3>
<ul>
<li><p>We talk about vowel quality in terms of “formants”</p></li>
<li><p>These are bands of the spectrum where the energy is
strongest</p></li>
<li><p>The frequencies of these formants are our primary cues</p></li>
<li><p>Bandwidth and power of these formants can be helpful too</p></li>
</ul>
<hr />
<p><img class="big" src="phonmedia/iformants.png"></p>
<hr />
<p><img class="big" src="phonmedia/iformantslabeled.png"></p>
<hr />
<h3 id="vowel-formants">Vowel formants</h3>
<ul>
<li><p>F1 and F2 are generally considered to be the most
important</p></li>
<li><p>F3 is good for rounding and rhoticity</p></li>
<li><p>We talk about them in terms of frequency, because that’s their
most crucial characteristic</p></li>
</ul>
<hr />
<h3 id="formants-alone-can-be-enough-for-some-perception">Formants alone
can be enough for some perception!</h3>
<hr />
<h3 id="sine-wave-speech">Sine Wave Speech</h3>
<ul>
<li>Take an existing speech sample, and generate sine waves
approximating the formants</li>
</ul>
<hr />
<p><img class="big" src="phonmedia/thanksforattending.png"></p>
<hr />
<h3 id="sample-sine-wave-speech">Sample Sine Wave Speech</h3>
<p>F1: <audio controls>
<source src="phonmedia/thanksforattendingf1.mp3" type="audio/mp3">
</audio></p>
<p>F2: <audio controls>
<source src="phonmedia/thanksforattendingf2.mp3" type="audio/mp3">
</audio></p>
<p>F3: <audio controls>
<source src="phonmedia/thanksforattendingf3.mp3" type="audio/mp3">
</audio></p>
<p>Combined: <audio controls>
<source src="phonmedia/thanksforattendingsine.mp3" type="audio/mp3">
</audio></p>
<p>Original: <audio controls>
<source src="phonmedia/thanksforattendingorig.mp3" type="audio/mp3">
</audio></p>
<hr />
<h3 id="theres-more-to-vowels-than-formants">There’s more to vowels than
formants</h3>
<ul>
<li><p>Formants tell us nothing about F0</p></li>
<li><p>Things like voice quality and nasality have other spectral
reflexes</p></li>
<li><p>“Secondary” spectral cues like formant amplitude and spectral
tilt can overwhelm formant cues</p></li>
<li><p>Vowel recognition is possible just using overall spectral
shape</p>
<ul>
<li>But this can start to approximate formants quickly!</li>
</ul></li>
<li><p>But we just keep coming back to formants as the primary cue to
vowel place</p></li>
</ul>
<hr />
<h3 id="so-we-think-about-vowels-in-terms-of-formants">So, we think
about vowels in terms of formants</h3>
<hr />
<p><img class="big" src="phonmedia/vowelformants.gif"></p>
<p><small>Different American English vowels, as spoken by a male
speaker</small></p>
<hr />
<h3 id="vowel-formants-are-reflections-of-articulations">Vowel formants
are reflections of articulations</h3>
<hr />
<h3 id="the-ipa-chart-is-acoustic">The IPA chart is acoustic!</h3>
<hr />
<p><img class="big" src="phonmedia/ipaformantsoverlay.png"></p>
<hr />
<p><img class="big" src="phonmedia/ipaformantsgraph.png"></p>
<hr />
<p><img class="big" src="humorimg/conspiracykeanu.jpg"></p>
<hr />
<p><img class="big" src="phonmedia/vowelformantsarticulation.png"></p>
<hr />
<p>So…</p>
<ul>
<li><p>We listen for formants</p></li>
<li><p>We figure out their frequencies</p></li>
<li><p>Then we know which vowel we’re hearing.</p></li>
<li><h3 id="whats-the-problem">What’s the problem?</h3></li>
</ul>
<hr />
<h1 id="language-is-crazy">Language is crazy</h1>
<ul>
<li>(In Linguistics, that’s <em>always</em> the problem)</li>
</ul>
<hr />
<h3 id="why-is-vowel-perception-hard">Why is vowel perception hard?</h3>
<ul>
<li><p>Vowel differences are gradient</p></li>
<li><p>Dialect and language variation is everywhere</p></li>
<li><p>Speakers vary from person to person. <em>A lot!</em></p></li>
<li><p>Speakers also vary from moment-to-moment</p></li>
</ul>
<hr />
<h2 id="perceptual-gradience">Perceptual Gradience</h2>
<hr />
<h3 id="perceptual-gradience-1">Perceptual Gradience</h3>
<ul>
<li><p>You can make an infinite number of tongue shapes causing an
infinite number of vowels.</p></li>
<li><p>There’s no “alveolar ridge” to give a steady target</p></li>
<li><p>Phonemes have perceptual boundaries</p>
<ul>
<li>Vowels with formant values in between phonemes are rough</li>
</ul></li>
<li><p>Not all listeners agree on where the boundaries are between, say,
/e/ and /ɛ/</p></li>
</ul>
<hr />
<h3 id="date-vs.-debt">Date vs. Debt</h3>
<p>Date: <audio controls>
<source src="phonmedia/date1.mp3" type="audio/mp3"> </audio></p>
<p>Debt: <audio controls>
<source src="phonmedia/date12.mp3" type="audio/mp3"> </audio></p>
<p>?: <audio controls>
<source src="phonmedia/date4.mp3" type="audio/mp3"> </audio></p>
<p>??: <audio controls>
<source src="phonmedia/date8.mp3" type="audio/mp3"> </audio></p>
<p>???: <audio controls>
<source src="phonmedia/date6.mp3" type="audio/mp3"> </audio></p>
<hr />
<h3 id="lets-do-an-experiment">Let’s do an experiment!</h3>
<audio controls>
<source src="phonmedia/date_debt_11_steps.mp3" type="audio/mp3">
</audio>
<hr />
<p>The first and last sounds have formants like the typical English /eɪ/
and /ɛ/vowels</p>
<p><img src="phonmedia/datedebtspectrogram.png"></p>
<audio controls>
<source src="phonmedia/date_debt_11_steps.mp3" type="audio/mp3">
</audio>
<hr />
<p>… but in the middle, we’re not really sure what’s going on</p>
<p><img src="phonmedia/datedebtspectrogram.png"></p>
<hr />
<h2
id="phonemic-inventory-plays-a-major-role-in-categorization">Phonemic
Inventory plays a major role in categorization!</h2>
<hr />
<h3 id="language-as-a-perceptual-factor">Language as a perceptual
factor</h3>
<ul>
<li><p>The vowel inventory in a language has a strong effect on the
perception of vowels</p></li>
<li><p>If you have lots of vowels, each one gets less acoustic (and
perceptual) elbow room</p></li>
</ul>
<hr />
<h3 id="spanish">Spanish</h3>
<p><img class="big" src="phonmedia/vowelcharts_spanish.png"></p>
<hr />
<h3 id="english">English</h3>
<p><img class="big" src="phonmedia/vowelcharts_english.png"></p>
<hr />
<h3 id="swedish">Swedish</h3>
<p><img class="big" src="phonmedia/vowelcharts_swedish.jpg"></p>
<hr />
<h2 id="speaker-variation">Speaker Variation!</h2>
<hr />
<h3 id="speaker-vowel-space-variation">Speaker Vowel Space
Variation</h3>
<ul>
<li><p>Different speakers produce different resonances, even for the
“same” vowels</p>
<ul>
<li>Vocal tracts can be shorter, longer, wider…</li>
</ul></li>
</ul>
<hr />
<p><img class="big" src="ling_memes/vocaltract.jpg"></p>
<hr />
<h3 id="speaker-vowel-space-variation-1">Speaker Vowel Space
Variation</h3>
<p>Different speakers produce different resonances, even for the “same”
vowels</p>
<ul>
<li><p>Speaker can have colds or allergies, can have more ‘nasal’
voices…</p></li>
<li><p>Sociolinguistic factors galore</p></li>
<li><p>Every person has a different set of basic vowel formant
positions</p>
<ul>
<li>This is called the speaker’s “vowel space”</li>
</ul></li>
</ul>
<hr />
<p><img class="big" src="phonmedia/ipaformantsgraph.png"></p>
<hr />
<p><img class="big" src="phonmedia/clearspeech_speakeraverages.png"></p>
<hr />
<h3 id="some-people-even-acknowledge-this">Some people even acknowledge
this</h3>
<ul>
<li>“Yeah, sure, there’s some variation, but no big deal, it’s OK…”</li>
</ul>
<hr />
<p><img class="big" src="phonmedia/vowelchart_variation.jpg"></p>
<hr />
<p><img class="big" src="phonmedia/vowelchart_variation2.jpg"></p>
<hr />
<h2 id="but-its-even-worse-than-it-seems">But it’s even worse than it
seems…</h2>
<hr />
<h3 id="moment-to-moment-vowel-variation">Moment-to-moment Vowel
Variation</h3>
<ul>
<li><p>Even the same speaker will have variation from moment to
moment</p></li>
<li><p>Sometimes we misarticulate, accidentally making the wrong vowel
quality</p>
<ul>
<li><p>Or we talk with food in our mouths, producing different
resonances</p></li>
<li><p>Or sometimes, we’re just plain lazy</p></li>
</ul></li>
<li><p>This leads to constant and massive changes in vowel
production</p></li>
</ul>
<hr />
<p><img class="big" src="phonmedia/clearspeech_speakeraverages.png"></p>
<hr />
<p><img class="big" src="phonmedia/clearspeech_alltokens.png"></p>
<hr />
<p><img class="big" src="phonmedia/clearspeech_alltokensellipses.png"></p>
<hr />
<p><img class="big" src="humorimg/trainwreck.png"></p>
<hr />
<h3
id="every-person-youve-ever-talked-with-has-had-different-vowel-formant-patterns">Every
person you’ve ever talked with has had different vowel formant
patterns</h3>
<ul>
<li>… and yet, we understand each other, somehow</li>
</ul>
<hr />
<h2 id="see-i-told-you-magic">See, I told you: Magic</h2>
<p><img class="small" src="img/magic.jpg"></p>
<hr />
<h3 id="how-do-we-accomplish-this-perceptual-magic">How do we accomplish
this perceptual magic?</h3>
<hr />
<h3 id="dealing-with-vowel-variability">Dealing with vowel
variability</h3>
<ul>
<li><p>We stack the deck in our favor using the phonology of the
language</p></li>
<li><p>We use non-formant-related cues such as vowel length</p></li>
<li><p>We attend to context</p></li>
<li><p>We adjust to individual speakers (or vocal tracts) through
Speaker Normalization</p></li>
<li><p>Then, if all else fails, we pretend that we understood, and hope
for the best</p></li>
</ul>
<hr />
<h2 id="dirty-phonological-tricks">Dirty Phonological Tricks</h2>
<hr />
<h3 id="vowel-inventories-are-designed-for-perceptibility">Vowel
Inventories are designed for perceptibility</h3>
<ul>
<li>Vowels are spread through the mouth</li>
</ul>
<hr />
<h3 id="spanish-1">Spanish</h3>
<p><img class="big" src="phonmedia/vowelcharts_spanish.png"></p>
<hr />
<h3 id="english-1">English</h3>
<p><img class="big" src="phonmedia/vowelcharts_english.png"></p>
<hr />
<h3 id="swedish-1">Swedish</h3>
<p><img class="big" src="phonmedia/vowelcharts_swedish.jpg"></p>
<hr />
<h3 id="vowel-inventories-are-designed-for-perceptibility-1">Vowel
Inventories are designed for perceptibility</h3>
<p>Vowels are spread through the mouth</p>
<ul>
<li><p>Languages try to maintain perceptual contrast (to keep things as
perceptually unambiguous as possible)</p>
<ul>
<li>/i, e, a, o, u/ more common than /i, y, e, œ, ɛ/</li>
</ul></li>
<li><p>Contrasts that are tough to hear go away!</p></li>
<li><p>Rounding is used to distinguish vowels which might otherwise be
confusable</p>
<ul>
<li>/i, u/ not /y, u/</li>
</ul></li>
</ul>
<hr />
<h3 id="vowel-length-can-help-too">Vowel Length can help too!</h3>
<ul>
<li>English tense vowels (/i, e, o, æ, ɔ, ɑ/) are longer than lax vowels
(/ɪ, ʊ, ʌ, ɛ/)</li>
</ul>
<p><img src="phonmedia/rositzke1939length.png"></p>
<p><small>Data from Rositske 1939</small></p>
<hr />
<h2 id="context-helps">Context helps!</h2>
<hr />
<h3 id="the-role-of-context">The Role of Context</h3>
<ul>
<li><p>Context helps us to understand words even if the phonemes are
acoustically ambiguous</p></li>
<li><p>Easier to understand “Hello” in its normal conversational
context</p></li>
<li><p>If you’re not expecting a word, you’ll have to fight harder to
understand it.</p>
<ul>
<li><p>“Hi, John! Partial Nephrectomy!”</p></li>
<li><p>“Ohh, Invasive Adenocarcinoma arising in tubulovillious
adenoma”</p></li>
</ul></li>
<li><p>Nobody runs into rooms and shouts “bat!”</p></li>
</ul>
<hr />
<h2 id="speaker-normalization">Speaker Normalization</h2>
<hr />
<h3 id="speaker-normalization-1">Speaker Normalization</h3>
<ul>
<li><p>Every speaker you meet has acoustically different vowels</p></li>
<li><p>We are able to adjust very quickly, and have little trouble with
later understanding</p></li>
<li><p>The process by which we adjust is called “Speaker
Normalization”</p></li>
<li><p>This process isn’t entirely understood</p>
<ul>
<li>That’s a <em>massive</em> understatement</li>
</ul></li>
</ul>
<table style="width:6%;">
<colgroup>
<col style="width: 5%" />
</colgroup>
<tbody>
<tr class="odd">
<td>### History of Normalization</td>
</tr>
<tr class="even">
<td>* Differences in absolute vowel qualities were noted very early
on</td>
</tr>
<tr class="odd">
<td>* Two Competing Theories in the 40’s and 50’s:</td>
</tr>
<tr class="even">
<td>* Peterson: We identify vowels based on their absolute formant
frequencies</td>
</tr>
<tr class="odd">
<td>* Joos: We identify vowels based on their relative formant
structures</td>
</tr>
<tr class="even">
<td>* If Joos is right, then prior context aids in normalization</td>
</tr>
<tr class="odd">
<td>* Ladefoged and Broadbent set out to test that idea in “Information
conveyed by vowels” in 1957</td>
</tr>
</tbody>
</table>
<h3 id="information-conveyed-by-vowels"><em>Information Conveyed by
Vowels</em></h3>
<ul>
<li><p>Ladefoged and Broadbent 1957</p></li>
<li><p>Six versions of an introductory sentence were synthesized, each
with different formant structures</p></li>
<li><p>Four test words were synthesized as well</p></li>
<li><p>Listeners heard different combinations of test words and
sentences</p></li>
<li><p><em>If vowel perception is about absolute frequencies, the prior
sentence shouldn’t matter!</em></p></li>
</ul>
<hr />
<h2
id="section"><img class="big" src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_chart1.png"></h2>
<h2
id="section-1"><img class="big" src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_chart2.png"></h2>
<h1 id="section-2">1957!</h1>
<hr />
<p>They had to paint what they wanted on glass</p>
<p><img class="big" src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_glassslide.png"></p>
<table style="width:6%;">
<colgroup>
<col style="width: 5%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Then feed it into an analog sound synthesizer</td>
</tr>
<tr class="even">
<td><img class="big" src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_machine.png"></td>
</tr>
</tbody>
</table>
<h3 id="the-results-werent-too-pretty">The results weren’t too
pretty</h3>
<p>Stimulus #4: <audio controls>
<source src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_please4.mp3" type="audio/mp3">
</audio></p>
<p>Stimulus #5:</p>
<audio controls>
<source src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_please5.mp3" type="audio/mp3">
</audio>
<p>Stimulus #6:</p>
<audio controls>
<source src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_please6.mp3" type="audio/mp3">
</audio>
<hr />
<p>… but it worked!</p>
<hr />
<h3 id="different-contexts-led-to-different-perception">Different
contexts led to different perception!</h3>
<p><img class="big" src="phonmedia/ladefogedbroadbent/ladefogedbroadbent_graph.png"></p>
<hr />
<h3 id="ladefoged-and-broadbent-conclusions">Ladefoged and Broadbent:
Conclusions</h3>
<blockquote>
<p>“The linguistic information conveyed by a vowel is largely dependent
on the relations between the frequencies of its formants and the
formants of other vowels occurring in the same auditory context”</p>
</blockquote>
<ul>
<li>This set the stage for future work in normalization!</li>
</ul>
<hr />
<h2 id="so-uh-hows-that-work-going">So, uh, how’s that work going?</h2>
<hr />
<p>We’ve got two main theories!</p>
<hr />
<h3 id="speaker-intrinsic-vowel-space-normalization">Speaker-intrinsic
vowel space normalization</h3>
<ul>
<li><p>Normalization is a process that “happens”</p></li>
<li><p>You meet somebody, you create a model of their vowel space, and
you move on</p></li>
<li><p>These models of speaker vowels are maintained in memory</p></li>
<li><p>One model per person, and a new model each time!</p></li>
</ul>
<hr />
<h3 id="speaker-extrinsic-vowel-space-normalization">Speaker-extrinsic
vowel space normalization</h3>
<ul>
<li><p>We store information from <em>every vowel we hear</em>!</p></li>
<li><p>Normalization is then just bulk comparison and probability</p>
<ul>
<li>Vowel identities are probabilistically determined</li>
</ul></li>
<li><p>One might start with an “English” vowels model</p></li>
<li><p>Then, you build a per-speaker exemplar cloud</p></li>
<li><p>Both your per-speaker and overall models change</p></li>
</ul>
<hr />
<p><img class="big" src="phonmedia/clearspeech_alltokens.png"></p>
<hr />
<h3 id="we-dont-know-which-is-more-accurate">We don’t know which is more
accurate!</h3>
<hr />
<h3 id="what-do-we-know-about-normalization">What do we know about
normalization?</h3>
<ul>
<li><p>It’s not just about the point vowels (/i, a, u/) as Joos
suggested (Verbrugge et. al. 1976)</p></li>
<li><p>Context influences Normalization (as in Ladefoged and
Broadbent)</p></li>
<li><p>Knowledge about the speaker (gender, sociolinguistic data)
influences normalization (Strand 2000)</p></li>
<li><p>Recent context might be more important than older context
(Ciocca, Wong, et al. 2006)</p></li>
<li><p>The normalization process shows up in reaction time during vowel
identification tasks (Haggard and Summerfield 1977)</p></li>
</ul>
<hr />
<h3 id="what-else-do-we-know-about-normalization">What else do we know
about normalization?</h3>
<ul>
<li><p>Breath sounds don’t provide good information for normalization,
and F0 isn’t a critical factor (Whalen &amp; Sheffert 1997)</p></li>
<li><p>More context seems helpful, but only to a certain point (Kakehi
1992)</p></li>
<li><p>We have to normalize consonants too</p>
<ul>
<li>Some evidence that vowel formants are used to normalize /s/
vs. /ʃ/</li>
</ul></li>
<li><p>Vowel nasality appears to require normalization too (Styler (to
appear))</p></li>
<li><p>Infants can normalize to vowels (Kuhl 1979)</p></li>
<li><p>So can dogs (Baru 1975) and Zebra Finches (Ohms et al
2009)</p></li>
</ul>
<hr />
<p>These finches are a <em>major</em> problem.</p>
<hr />
<section data-background="phonmedia/zebrafinch_intrinsic.jpg">
</section>
<hr />
<section data-background="phonmedia/zebrafinch_extrinsic.jpg">
</section>
<hr />
<section data-background="phonmedia/zebrafinch_takethat.jpg">
</section>
<hr />
<h3
id="this-suggests-that-normalization-may-be-a-more-general-cognitive-process">This
suggests that normalization may be a more general cognitive process</h3>
<ul>
<li><p>Other animals show awareness of vocal tract size differences</p>
<ul>
<li>‘Female koalas prefer bellows in which lower formants indicate
larger males’ (Charlton et al 2012)</li>
</ul></li>
<li><p>“Attributing variation to cause” is something we’re generally
good at</p>
<ul>
<li><h2 id="color-normalization">Color Normalization</h2></li>
</ul></li>
</ul>
<p><img class="big" src="phonmedia/the_dress.png"></p>
<table style="width:6%;">
<colgroup>
<col style="width: 5%" />
</colgroup>
<thead>
<tr class="header">
<th><img class="big" src="img/checkerboard_illusion.png"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img class="big" src="img/checkerboard_illusion_line.png"></td>
</tr>
</tbody>
</table>
<p>“OK, OK, we get it. Nothing’s real. Everybody varies. Speech study is
impossible. Let’s change to syntax.”</p>
<hr />
<h2 id="how-do-we-cope-as-researchers">How do we cope as
researchers?</h2>
<hr />
<h3 id="mathematical-normalization">Mathematical Normalization</h3>
<ul>
<li>Not cognitive theories, but useful for people who want vowel
variation “out of their way”</li>
</ul>
<blockquote>
<p>“Various algorithms have already been proposed for this purpose. The
criterion for their degree of success might be that they should
maximally reduce the variance within each group of vowels presumed to
represent the same target when spoken by different speakers, while
maintaining the separation between such groups of vowels presumed to
represent different targets.” (Disner 1979)</p>
</blockquote>
<ul>
<li><p>Allows for more principled across-speaker comparison</p></li>
<li><p>Statistical in nature, rather than contextual or
“linguistic”</p></li>
</ul>
<hr />
<h3 id="lobanov-1971-normalization">Lobanov (1971) Normalization</h3>
<p><img src="phonmedia/lobanov_equation.gif"></p>
<ul>
<li><p>σ is the Standard Deviation of all tokens around the vowel
mean</p></li>
<li><p>Done for each formant, for each vowel</p></li>
<li><p>Leaves you with formant points for each token which are more
comparable across speakers</p></li>
<li><p>This can be done on your own, or using <a
href="http://lingtools.uoregon.edu/norm/norm1.php">NORM</a> or vowels()
in R</p></li>
</ul>
<hr />
<h2 id="danger">Danger!!</h2>
<p><img class="small" src="img/schwaandcrossphones.png"></p>
<hr />
<h2 id="vowel-normalization-is-imperfect"><strong>Vowel Normalization is
imperfect</strong></h2>
<ul>
<li><p>It reduces across-speaker variability, but doesn’t remove it
completely</p></li>
<li><p>The end results are suitable only for rough comparison among
speakers</p>
<ul>
<li>The resulting numbers are abstractions</li>
</ul></li>
<li><p>Disner finds these algorithms good within language</p>
<ul>
<li>But for cross-language analyses, things get dangerous</li>
</ul></li>
<li><p><strong>Don’t pretend it’s solved the problem!</strong></p>
<ul>
<li>It’s just makes it possible to make basic comparisons</li>
</ul></li>
</ul>
<table style="width:6%;">
<colgroup>
<col style="width: 5%" />
</colgroup>
<tbody>
<tr class="odd">
<td>### Wrapping up</td>
</tr>
<tr class="even">
<td>* Formants (F1 &amp; F2) are the primary means of identifying
vowels</td>
</tr>
<tr class="odd">
<td>* Vowel charts, although well-intentioned, are dirty, dirty
abstractions</td>
</tr>
<tr class="even">
<td>* Vowel perception is complicated by the enormous variation between
speakers and tokens</td>
</tr>
<tr class="odd">
<td>* Phonology, Context, and Secondary Cues help to make things
perceptually easier</td>
</tr>
<tr class="even">
<td>* There’s not a strong consensus on how exactly we normalize across
speakers</td>
</tr>
<tr class="odd">
<td>- Or how Zebra finches do</td>
</tr>
<tr class="even">
<td>* Vowel perception is basically magic</td>
</tr>
</tbody>
</table>
<section data-background="img/hogwarts.jpg">
</section>
<hr />
<p><huge>Thank you!</huge></p>
<p>http://savethevowels.org/talks/vowelperception_advanced.html</p>
<hr />
<h1 id="references">References</h1>
<pre><code>Baru, A. V. (1975). Discrimination of synthesized vowels /a/ and /i/ with varying parameters (f0, intensity, duration, # of formants) in dog. In G. Fant, &amp; M. A. A. Tatham (Eds.), Auditory Analysis and perception of speech. New York: Academic Press.

Ciocca, V., Wong, N. K. Y., Leung, W. H. Y., &amp; Chu, P. C. Y. (2006). Extrinsic context affects perceptual normalization of lexical tone. The Journal of the Acoustical Society of America, Vol. 119, No. 3, 1712-1726.

Charlton, B. D., Ellis, W. A. H., Brumm, J., Nilsson, K., and Fitch, W. T. (2012). Female koalas prefer bellows in which lower formants indicate larger males. Animal Behaviour, 84(6):1565– 1571.

Disner, S.F. (1980).  Evaluation of vowel normalization procedures. The Journal of the Acoustical Society of America, Vol 67(1), 253-261. 

Joos, M. (1948). Acoustic Phonetics - Supplement to Language. Baltimore: Linguistic Society of America.

Ladefoged, P., &amp; Broadbent, D. E. (1957). Information Conveyed by Vowels. The Journal of the Acoustical Society of America, Volume 29, Number 1, 98-104.

Lobanov, B. (1971). Classification of Russian Vowels Spoken by Different Speakers. The Journal of the Acoustical Society of America, 49(2B):606–608.

Ohms et al. Zebra finches exhibit speaker-independent phonetic perception of human speech. Proceedings of the The Royal Society of Biological Sciences (2009)

Rositzke, H. A. (1939). Vowel-Length in General American Speech. Language, Vol. 15, No. 2, 99-109.

Verbrugge, R. R., Strange, W., Shankweiler, D. P., &amp; Edman, T. R. (1976). What information enables a listener to map a talker&#39;s vowel space? Journal of the Acoustical Society of America, Vol. 60, No. 1, 198-212.

Whalen, D. H., &amp; Sheffert, S. M. (1997). Normalization of Vowels by Breath Sounds. In K. Johnson, &amp; J. W. Mullenix (Eds.), Talker Variability in Speech Processing (pp. 133-143). San Diego, CA: Academic Press Ltd.</code></pre>
<hr />
</body>
</html>
